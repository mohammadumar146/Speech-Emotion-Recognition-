{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1BBSud7qfr5FJp0d3LKh9FqoCvbcypxw_",
      "authorship_tag": "ABX9TyMlL6yjBV52FVsthys15zUx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadumar146/Speech-Emotion-Recognition-/blob/main/CNN_Model_NEw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O4HIXwzbT4R",
        "outputId": "58fed9d1-fef4-430c-e80c-b342b99c8c4f"
      },
      "source": [
        "pip install librosa soundfile numpy sklearn pyaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.11.tar.gz (37 kB)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyaudio\n",
            "Failed to build pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "    Running setup.py install for pyaudio ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qjrhra1c/pyaudio_d886b059e9be42c3aa4610adf481371c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qjrhra1c/pyaudio_d886b059e9be42c3aa4610adf481371c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-la63sq1v/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/pyaudio Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5UntFnUQYSf"
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFqANqbcQbnT"
      },
      "source": [
        "#Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "               #X = sound_file.read()\n",
        "        sample_rate=sound_file.samplerate\n",
        "        X, sample_rate = librosa.load(file_name)\n",
        "        #sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result=np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma1=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, chroma1))\n",
        "        if mel:\n",
        "            mel1=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, mel1))\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRA77WtIQd7P"
      },
      "source": [
        "#Emotions in the  dataset\n",
        "emotions={\n",
        "  '03':'03',\n",
        "  '02':'02',\n",
        "  '04':'04',\n",
        "  '01':'01',\n",
        "}\n",
        "# - Emotions to observe\n",
        "observed_emotions=['01', '02', '03', '04']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqWguBrjQgYz"
      },
      "source": [
        "# - Load the data and extract features for each sound file\n",
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    for file in glob.glob(\"./drive/My Drive/data/Emotion_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[1]]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "        feature = [int(x) for x in feature] \n",
        "       # emotion =[float(y) for y in emotion]\n",
        "       # print(emotion)\n",
        "\n",
        "    return train_test_split(np.asarray(x), np.asarray(y), test_size=test_size, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm--9JkMQijN"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.23, random_state=42)\n",
        "# - Split the dataset\n",
        "x_train, x_test, y_train, y_test = load_data(test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WyL3mSJQk4c",
        "outputId": "c73e385c-d3ba-41c5-9b9b-7815962f6b13"
      },
      "source": [
        "# - Get the shape of the training and testing datasets\n",
        "#print(y_test.shape[0])\n",
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(461, 154)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPa7662DB9k"
      },
      "source": [
        "X_train = np.array(x_train)\n",
        "y_train = np.array(y_train).ravel()\n",
        "X_test = np.array(x_test)\n",
        "y_test = np.array(y_test).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2juXvtFEodv"
      },
      "source": [
        "# One-Hot Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyWp5NYLFcdO"
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKJ7qDX4Fk8b",
        "outputId": "6b0cc430-60f8-4e1a-c01e-51266a4f113e"
      },
      "source": [
        "# To build Neural Network and Create desired Model\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D #, AveragePooling1D\n",
        "from keras.layers import Flatten, Dropout, Activation # Input, \n",
        "from keras.layers import Dense #, Embeddi\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(256, 5,padding='same',\n",
        "                 input_shape=(x_traincnn.shape[1],x_traincnn.shape[2])))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyK9DFJFF5G_",
        "outputId": "1105c4cc-2bef-4ff3-d3c6-3cf88f43e6dd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 180, 256)          1536      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 180, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 180, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 180, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 180, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 22, 128)           82048     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 22, 128)           82048     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2816)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 11268     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 340,868\n",
            "Trainable params: 340,868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B69PTl3pF_EZ"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zStLaL-gGCqD",
        "outputId": "374cae26-5fe3-4548-c0f5-ce822765d647"
      },
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "29/29 [==============================] - 21s 131ms/step - loss: 1.2422 - accuracy: 0.4415 - val_loss: 1.2292 - val_accuracy: 0.4870\n",
            "Epoch 2/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 1.0895 - accuracy: 0.5891 - val_loss: 1.1781 - val_accuracy: 0.5455\n",
            "Epoch 3/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 1.0632 - accuracy: 0.5967 - val_loss: 1.1103 - val_accuracy: 0.6494\n",
            "Epoch 4/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.9858 - accuracy: 0.6681 - val_loss: 1.0760 - val_accuracy: 0.6299\n",
            "Epoch 5/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.9602 - accuracy: 0.6738 - val_loss: 1.0326 - val_accuracy: 0.6688\n",
            "Epoch 6/500\n",
            "29/29 [==============================] - 3s 101ms/step - loss: 0.9533 - accuracy: 0.7194 - val_loss: 1.0082 - val_accuracy: 0.6818\n",
            "Epoch 7/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.8567 - accuracy: 0.7292 - val_loss: 0.9641 - val_accuracy: 0.7143\n",
            "Epoch 8/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.9091 - accuracy: 0.7036 - val_loss: 0.9490 - val_accuracy: 0.7338\n",
            "Epoch 9/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.8663 - accuracy: 0.7185 - val_loss: 0.9272 - val_accuracy: 0.7403\n",
            "Epoch 10/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.7826 - accuracy: 0.7628 - val_loss: 0.8992 - val_accuracy: 0.7468\n",
            "Epoch 11/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.7814 - accuracy: 0.7773 - val_loss: 0.9062 - val_accuracy: 0.7273\n",
            "Epoch 12/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.7960 - accuracy: 0.7600 - val_loss: 0.8689 - val_accuracy: 0.7662\n",
            "Epoch 13/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.7462 - accuracy: 0.7572 - val_loss: 0.8346 - val_accuracy: 0.7597\n",
            "Epoch 14/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.6881 - accuracy: 0.7849 - val_loss: 0.8374 - val_accuracy: 0.7727\n",
            "Epoch 15/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.7487 - accuracy: 0.7495 - val_loss: 0.8196 - val_accuracy: 0.7208\n",
            "Epoch 16/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.6886 - accuracy: 0.7526 - val_loss: 0.7717 - val_accuracy: 0.7922\n",
            "Epoch 17/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.6311 - accuracy: 0.8263 - val_loss: 0.7833 - val_accuracy: 0.7727\n",
            "Epoch 18/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.6843 - accuracy: 0.7592 - val_loss: 0.7539 - val_accuracy: 0.7922\n",
            "Epoch 19/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.6898 - accuracy: 0.7504 - val_loss: 0.7548 - val_accuracy: 0.7922\n",
            "Epoch 20/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.6938 - accuracy: 0.7875 - val_loss: 0.7465 - val_accuracy: 0.8117\n",
            "Epoch 21/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.6528 - accuracy: 0.7688 - val_loss: 0.7369 - val_accuracy: 0.8117\n",
            "Epoch 22/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5894 - accuracy: 0.8059 - val_loss: 0.7072 - val_accuracy: 0.7987\n",
            "Epoch 23/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.5630 - accuracy: 0.8261 - val_loss: 0.7360 - val_accuracy: 0.8052\n",
            "Epoch 24/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.5657 - accuracy: 0.8247 - val_loss: 0.6907 - val_accuracy: 0.8247\n",
            "Epoch 25/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5796 - accuracy: 0.8079 - val_loss: 0.6988 - val_accuracy: 0.8117\n",
            "Epoch 26/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5608 - accuracy: 0.8104 - val_loss: 0.7131 - val_accuracy: 0.8182\n",
            "Epoch 27/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.5605 - accuracy: 0.8257 - val_loss: 0.6993 - val_accuracy: 0.8052\n",
            "Epoch 28/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.5319 - accuracy: 0.8678 - val_loss: 0.6553 - val_accuracy: 0.8117\n",
            "Epoch 29/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5173 - accuracy: 0.8483 - val_loss: 0.6896 - val_accuracy: 0.8312\n",
            "Epoch 30/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5463 - accuracy: 0.8381 - val_loss: 0.6694 - val_accuracy: 0.8182\n",
            "Epoch 31/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.5535 - accuracy: 0.8161 - val_loss: 0.6575 - val_accuracy: 0.8506\n",
            "Epoch 32/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.5175 - accuracy: 0.8578 - val_loss: 0.6809 - val_accuracy: 0.8052\n",
            "Epoch 33/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.5233 - accuracy: 0.8350 - val_loss: 0.6480 - val_accuracy: 0.8247\n",
            "Epoch 34/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.5037 - accuracy: 0.8470 - val_loss: 0.6369 - val_accuracy: 0.8506\n",
            "Epoch 35/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.4961 - accuracy: 0.8292 - val_loss: 0.6187 - val_accuracy: 0.8377\n",
            "Epoch 36/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.4814 - accuracy: 0.8355 - val_loss: 0.6201 - val_accuracy: 0.8442\n",
            "Epoch 37/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.5034 - accuracy: 0.8477 - val_loss: 0.6195 - val_accuracy: 0.8377\n",
            "Epoch 38/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.4475 - accuracy: 0.8630 - val_loss: 0.6061 - val_accuracy: 0.8312\n",
            "Epoch 39/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.4999 - accuracy: 0.8406 - val_loss: 0.6136 - val_accuracy: 0.8377\n",
            "Epoch 40/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.4639 - accuracy: 0.8682 - val_loss: 0.6220 - val_accuracy: 0.8442\n",
            "Epoch 41/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.4312 - accuracy: 0.9029 - val_loss: 0.6098 - val_accuracy: 0.8636\n",
            "Epoch 42/500\n",
            "29/29 [==============================] - 3s 101ms/step - loss: 0.4591 - accuracy: 0.8711 - val_loss: 0.6164 - val_accuracy: 0.8377\n",
            "Epoch 43/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.4539 - accuracy: 0.8597 - val_loss: 0.5935 - val_accuracy: 0.8442\n",
            "Epoch 44/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.4437 - accuracy: 0.8150 - val_loss: 0.5802 - val_accuracy: 0.8506\n",
            "Epoch 45/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.4555 - accuracy: 0.8446 - val_loss: 0.5744 - val_accuracy: 0.8442\n",
            "Epoch 46/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3812 - accuracy: 0.9051 - val_loss: 0.5641 - val_accuracy: 0.8442\n",
            "Epoch 47/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.4002 - accuracy: 0.8716 - val_loss: 0.5644 - val_accuracy: 0.8571\n",
            "Epoch 48/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3553 - accuracy: 0.8977 - val_loss: 0.5479 - val_accuracy: 0.8506\n",
            "Epoch 49/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.4107 - accuracy: 0.8854 - val_loss: 0.5631 - val_accuracy: 0.8571\n",
            "Epoch 50/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.4206 - accuracy: 0.8910 - val_loss: 0.5654 - val_accuracy: 0.8506\n",
            "Epoch 51/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3926 - accuracy: 0.8598 - val_loss: 0.5675 - val_accuracy: 0.8182\n",
            "Epoch 52/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3647 - accuracy: 0.8966 - val_loss: 0.5609 - val_accuracy: 0.8442\n",
            "Epoch 53/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3866 - accuracy: 0.8899 - val_loss: 0.5552 - val_accuracy: 0.8506\n",
            "Epoch 54/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3582 - accuracy: 0.9094 - val_loss: 0.5525 - val_accuracy: 0.8571\n",
            "Epoch 55/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3733 - accuracy: 0.9015 - val_loss: 0.5576 - val_accuracy: 0.8442\n",
            "Epoch 56/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3747 - accuracy: 0.9087 - val_loss: 0.5376 - val_accuracy: 0.8506\n",
            "Epoch 57/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3513 - accuracy: 0.8962 - val_loss: 0.5574 - val_accuracy: 0.8571\n",
            "Epoch 58/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3415 - accuracy: 0.9119 - val_loss: 0.5317 - val_accuracy: 0.8571\n",
            "Epoch 59/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3816 - accuracy: 0.8756 - val_loss: 0.5375 - val_accuracy: 0.8571\n",
            "Epoch 60/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3573 - accuracy: 0.9143 - val_loss: 0.5278 - val_accuracy: 0.8636\n",
            "Epoch 61/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3762 - accuracy: 0.9092 - val_loss: 0.5375 - val_accuracy: 0.8571\n",
            "Epoch 62/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3282 - accuracy: 0.9134 - val_loss: 0.5370 - val_accuracy: 0.8636\n",
            "Epoch 63/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2971 - accuracy: 0.9281 - val_loss: 0.5160 - val_accuracy: 0.8701\n",
            "Epoch 64/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3584 - accuracy: 0.8843 - val_loss: 0.5113 - val_accuracy: 0.8701\n",
            "Epoch 65/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3150 - accuracy: 0.9221 - val_loss: 0.5066 - val_accuracy: 0.8766\n",
            "Epoch 66/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3043 - accuracy: 0.9361 - val_loss: 0.4982 - val_accuracy: 0.8571\n",
            "Epoch 67/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.3117 - accuracy: 0.9050 - val_loss: 0.5018 - val_accuracy: 0.8571\n",
            "Epoch 68/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2955 - accuracy: 0.9188 - val_loss: 0.5018 - val_accuracy: 0.8701\n",
            "Epoch 69/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2957 - accuracy: 0.9207 - val_loss: 0.5015 - val_accuracy: 0.8636\n",
            "Epoch 70/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2972 - accuracy: 0.9224 - val_loss: 0.5038 - val_accuracy: 0.8896\n",
            "Epoch 71/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2998 - accuracy: 0.9134 - val_loss: 0.4980 - val_accuracy: 0.8506\n",
            "Epoch 72/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2863 - accuracy: 0.8997 - val_loss: 0.5140 - val_accuracy: 0.8636\n",
            "Epoch 73/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.3003 - accuracy: 0.9167 - val_loss: 0.5010 - val_accuracy: 0.8701\n",
            "Epoch 74/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2945 - accuracy: 0.9164 - val_loss: 0.4938 - val_accuracy: 0.8636\n",
            "Epoch 75/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2711 - accuracy: 0.9286 - val_loss: 0.5038 - val_accuracy: 0.8636\n",
            "Epoch 76/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2584 - accuracy: 0.9327 - val_loss: 0.4950 - val_accuracy: 0.8636\n",
            "Epoch 77/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2502 - accuracy: 0.9387 - val_loss: 0.5100 - val_accuracy: 0.8766\n",
            "Epoch 78/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2296 - accuracy: 0.9439 - val_loss: 0.4879 - val_accuracy: 0.8571\n",
            "Epoch 79/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2694 - accuracy: 0.9345 - val_loss: 0.5038 - val_accuracy: 0.8636\n",
            "Epoch 80/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2835 - accuracy: 0.9142 - val_loss: 0.4964 - val_accuracy: 0.8896\n",
            "Epoch 81/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2618 - accuracy: 0.9388 - val_loss: 0.5021 - val_accuracy: 0.8766\n",
            "Epoch 82/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2619 - accuracy: 0.9442 - val_loss: 0.4956 - val_accuracy: 0.8701\n",
            "Epoch 83/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2405 - accuracy: 0.9442 - val_loss: 0.5225 - val_accuracy: 0.8701\n",
            "Epoch 84/500\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.2546 - accuracy: 0.9205 - val_loss: 0.5317 - val_accuracy: 0.8636\n",
            "Epoch 85/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2111 - accuracy: 0.9544 - val_loss: 0.5057 - val_accuracy: 0.8766\n",
            "Epoch 86/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2416 - accuracy: 0.9430 - val_loss: 0.5099 - val_accuracy: 0.8701\n",
            "Epoch 87/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2533 - accuracy: 0.9229 - val_loss: 0.5227 - val_accuracy: 0.8571\n",
            "Epoch 88/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2151 - accuracy: 0.9330 - val_loss: 0.5247 - val_accuracy: 0.8766\n",
            "Epoch 89/500\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.2160 - accuracy: 0.9329 - val_loss: 0.4924 - val_accuracy: 0.8831\n",
            "Epoch 90/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2381 - accuracy: 0.9435 - val_loss: 0.5047 - val_accuracy: 0.8766\n",
            "Epoch 91/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2323 - accuracy: 0.9323 - val_loss: 0.4988 - val_accuracy: 0.8831\n",
            "Epoch 92/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.2063 - accuracy: 0.9538 - val_loss: 0.4774 - val_accuracy: 0.8831\n",
            "Epoch 93/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.2342 - accuracy: 0.9402 - val_loss: 0.4900 - val_accuracy: 0.8701\n",
            "Epoch 94/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.2243 - accuracy: 0.9490 - val_loss: 0.4705 - val_accuracy: 0.8831\n",
            "Epoch 95/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1976 - accuracy: 0.9527 - val_loss: 0.4971 - val_accuracy: 0.8831\n",
            "Epoch 96/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.2007 - accuracy: 0.9568 - val_loss: 0.4772 - val_accuracy: 0.8896\n",
            "Epoch 97/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.2221 - accuracy: 0.9443 - val_loss: 0.4919 - val_accuracy: 0.8766\n",
            "Epoch 98/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1940 - accuracy: 0.9539 - val_loss: 0.5173 - val_accuracy: 0.8831\n",
            "Epoch 99/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.1845 - accuracy: 0.9492 - val_loss: 0.5289 - val_accuracy: 0.8701\n",
            "Epoch 100/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1741 - accuracy: 0.9698 - val_loss: 0.4991 - val_accuracy: 0.8961\n",
            "Epoch 101/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.2044 - accuracy: 0.9454 - val_loss: 0.4795 - val_accuracy: 0.8831\n",
            "Epoch 102/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1887 - accuracy: 0.9522 - val_loss: 0.4927 - val_accuracy: 0.8831\n",
            "Epoch 103/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.5251 - val_accuracy: 0.8896\n",
            "Epoch 104/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1890 - accuracy: 0.9387 - val_loss: 0.4890 - val_accuracy: 0.8961\n",
            "Epoch 105/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1802 - accuracy: 0.9654 - val_loss: 0.4966 - val_accuracy: 0.8896\n",
            "Epoch 106/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1828 - accuracy: 0.9610 - val_loss: 0.4849 - val_accuracy: 0.8831\n",
            "Epoch 107/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.1722 - accuracy: 0.9568 - val_loss: 0.5159 - val_accuracy: 0.8961\n",
            "Epoch 108/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1785 - accuracy: 0.9631 - val_loss: 0.4819 - val_accuracy: 0.8961\n",
            "Epoch 109/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1476 - accuracy: 0.9735 - val_loss: 0.4674 - val_accuracy: 0.8896\n",
            "Epoch 110/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1618 - accuracy: 0.9701 - val_loss: 0.4965 - val_accuracy: 0.8896\n",
            "Epoch 111/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1670 - accuracy: 0.9670 - val_loss: 0.4829 - val_accuracy: 0.8896\n",
            "Epoch 112/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1720 - accuracy: 0.9610 - val_loss: 0.4801 - val_accuracy: 0.8896\n",
            "Epoch 113/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1397 - accuracy: 0.9727 - val_loss: 0.4692 - val_accuracy: 0.8961\n",
            "Epoch 114/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1712 - accuracy: 0.9570 - val_loss: 0.4810 - val_accuracy: 0.8896\n",
            "Epoch 115/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1855 - accuracy: 0.9557 - val_loss: 0.4795 - val_accuracy: 0.8896\n",
            "Epoch 116/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1593 - accuracy: 0.9655 - val_loss: 0.5075 - val_accuracy: 0.8961\n",
            "Epoch 117/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1831 - accuracy: 0.9585 - val_loss: 0.4927 - val_accuracy: 0.8896\n",
            "Epoch 118/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1823 - accuracy: 0.9576 - val_loss: 0.4806 - val_accuracy: 0.8896\n",
            "Epoch 119/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.1286 - accuracy: 0.9835 - val_loss: 0.5016 - val_accuracy: 0.8896\n",
            "Epoch 120/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1597 - accuracy: 0.9535 - val_loss: 0.5065 - val_accuracy: 0.9026\n",
            "Epoch 121/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1535 - accuracy: 0.9611 - val_loss: 0.5072 - val_accuracy: 0.8831\n",
            "Epoch 122/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1484 - accuracy: 0.9614 - val_loss: 0.4794 - val_accuracy: 0.8896\n",
            "Epoch 123/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1245 - accuracy: 0.9810 - val_loss: 0.5070 - val_accuracy: 0.8896\n",
            "Epoch 124/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1504 - accuracy: 0.9740 - val_loss: 0.5233 - val_accuracy: 0.8961\n",
            "Epoch 125/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1472 - accuracy: 0.9667 - val_loss: 0.5345 - val_accuracy: 0.8961\n",
            "Epoch 126/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1317 - accuracy: 0.9848 - val_loss: 0.4850 - val_accuracy: 0.9026\n",
            "Epoch 127/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1427 - accuracy: 0.9797 - val_loss: 0.5060 - val_accuracy: 0.8896\n",
            "Epoch 128/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1624 - accuracy: 0.9352 - val_loss: 0.5277 - val_accuracy: 0.9026\n",
            "Epoch 129/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1203 - accuracy: 0.9662 - val_loss: 0.5042 - val_accuracy: 0.9026\n",
            "Epoch 130/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1357 - accuracy: 0.9623 - val_loss: 0.4833 - val_accuracy: 0.8896\n",
            "Epoch 131/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1148 - accuracy: 0.9830 - val_loss: 0.5213 - val_accuracy: 0.9091\n",
            "Epoch 132/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1161 - accuracy: 0.9835 - val_loss: 0.5168 - val_accuracy: 0.9156\n",
            "Epoch 133/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1216 - accuracy: 0.9739 - val_loss: 0.5205 - val_accuracy: 0.8831\n",
            "Epoch 134/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.1333 - accuracy: 0.9675 - val_loss: 0.4873 - val_accuracy: 0.8961\n",
            "Epoch 135/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.1535 - accuracy: 0.9606 - val_loss: 0.4943 - val_accuracy: 0.8961\n",
            "Epoch 136/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.1068 - accuracy: 0.9826 - val_loss: 0.4959 - val_accuracy: 0.9156\n",
            "Epoch 137/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.1320 - accuracy: 0.9575 - val_loss: 0.4795 - val_accuracy: 0.8961\n",
            "Epoch 138/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1138 - accuracy: 0.9757 - val_loss: 0.5056 - val_accuracy: 0.9091\n",
            "Epoch 139/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0952 - accuracy: 0.9778 - val_loss: 0.4977 - val_accuracy: 0.8961\n",
            "Epoch 140/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1134 - accuracy: 0.9724 - val_loss: 0.5028 - val_accuracy: 0.9026\n",
            "Epoch 141/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0988 - accuracy: 0.9862 - val_loss: 0.4780 - val_accuracy: 0.8961\n",
            "Epoch 142/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1032 - accuracy: 0.9903 - val_loss: 0.5113 - val_accuracy: 0.8831\n",
            "Epoch 143/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0913 - accuracy: 0.9750 - val_loss: 0.4755 - val_accuracy: 0.8896\n",
            "Epoch 144/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1055 - accuracy: 0.9733 - val_loss: 0.4800 - val_accuracy: 0.8896\n",
            "Epoch 145/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1148 - accuracy: 0.9745 - val_loss: 0.5158 - val_accuracy: 0.9026\n",
            "Epoch 146/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.1145 - accuracy: 0.9794 - val_loss: 0.4915 - val_accuracy: 0.8961\n",
            "Epoch 147/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0885 - accuracy: 0.9889 - val_loss: 0.5130 - val_accuracy: 0.9026\n",
            "Epoch 148/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0930 - accuracy: 0.9897 - val_loss: 0.5088 - val_accuracy: 0.8961\n",
            "Epoch 149/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0912 - accuracy: 0.9811 - val_loss: 0.5005 - val_accuracy: 0.8961\n",
            "Epoch 150/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0900 - accuracy: 0.9871 - val_loss: 0.5011 - val_accuracy: 0.8831\n",
            "Epoch 151/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0997 - accuracy: 0.9745 - val_loss: 0.5072 - val_accuracy: 0.8961\n",
            "Epoch 152/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0944 - accuracy: 0.9851 - val_loss: 0.4981 - val_accuracy: 0.8961\n",
            "Epoch 153/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0891 - accuracy: 0.9861 - val_loss: 0.5219 - val_accuracy: 0.9026\n",
            "Epoch 154/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0942 - accuracy: 0.9861 - val_loss: 0.5158 - val_accuracy: 0.8961\n",
            "Epoch 155/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0925 - accuracy: 0.9849 - val_loss: 0.4890 - val_accuracy: 0.8961\n",
            "Epoch 156/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0761 - accuracy: 0.9937 - val_loss: 0.4996 - val_accuracy: 0.9026\n",
            "Epoch 157/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0877 - accuracy: 0.9896 - val_loss: 0.5357 - val_accuracy: 0.8961\n",
            "Epoch 158/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0686 - accuracy: 0.9922 - val_loss: 0.5286 - val_accuracy: 0.9026\n",
            "Epoch 159/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0922 - accuracy: 0.9753 - val_loss: 0.5008 - val_accuracy: 0.8961\n",
            "Epoch 160/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0834 - accuracy: 0.9798 - val_loss: 0.5263 - val_accuracy: 0.8961\n",
            "Epoch 161/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0722 - accuracy: 0.9957 - val_loss: 0.5221 - val_accuracy: 0.9091\n",
            "Epoch 162/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0798 - accuracy: 0.9992 - val_loss: 0.5244 - val_accuracy: 0.9026\n",
            "Epoch 163/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0708 - accuracy: 0.9920 - val_loss: 0.5088 - val_accuracy: 0.8961\n",
            "Epoch 164/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0845 - accuracy: 0.9827 - val_loss: 0.5112 - val_accuracy: 0.9091\n",
            "Epoch 165/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0812 - accuracy: 0.9826 - val_loss: 0.5350 - val_accuracy: 0.8961\n",
            "Epoch 166/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0717 - accuracy: 0.9923 - val_loss: 0.5069 - val_accuracy: 0.8961\n",
            "Epoch 167/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0762 - accuracy: 0.9884 - val_loss: 0.5503 - val_accuracy: 0.8896\n",
            "Epoch 168/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0662 - accuracy: 0.9914 - val_loss: 0.5034 - val_accuracy: 0.8896\n",
            "Epoch 169/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0763 - accuracy: 0.9861 - val_loss: 0.5207 - val_accuracy: 0.8961\n",
            "Epoch 170/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0751 - accuracy: 0.9790 - val_loss: 0.5457 - val_accuracy: 0.9026\n",
            "Epoch 171/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0681 - accuracy: 0.9899 - val_loss: 0.5065 - val_accuracy: 0.8961\n",
            "Epoch 172/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0750 - accuracy: 0.9868 - val_loss: 0.5632 - val_accuracy: 0.9026\n",
            "Epoch 173/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0565 - accuracy: 0.9939 - val_loss: 0.5144 - val_accuracy: 0.8961\n",
            "Epoch 174/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0752 - accuracy: 0.9983 - val_loss: 0.5326 - val_accuracy: 0.9091\n",
            "Epoch 175/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0696 - accuracy: 0.9926 - val_loss: 0.5164 - val_accuracy: 0.8961\n",
            "Epoch 176/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0724 - accuracy: 0.9973 - val_loss: 0.5611 - val_accuracy: 0.9026\n",
            "Epoch 177/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0673 - accuracy: 0.9949 - val_loss: 0.5263 - val_accuracy: 0.8961\n",
            "Epoch 178/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0630 - accuracy: 0.9952 - val_loss: 0.5525 - val_accuracy: 0.9026\n",
            "Epoch 179/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0621 - accuracy: 0.9869 - val_loss: 0.5363 - val_accuracy: 0.9091\n",
            "Epoch 180/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0615 - accuracy: 0.9881 - val_loss: 0.5314 - val_accuracy: 0.8961\n",
            "Epoch 181/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0564 - accuracy: 0.9981 - val_loss: 0.5509 - val_accuracy: 0.8961\n",
            "Epoch 182/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0529 - accuracy: 0.9986 - val_loss: 0.5391 - val_accuracy: 0.9026\n",
            "Epoch 183/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0463 - accuracy: 0.9907 - val_loss: 0.5369 - val_accuracy: 0.8961\n",
            "Epoch 184/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0578 - accuracy: 0.9956 - val_loss: 0.5743 - val_accuracy: 0.9026\n",
            "Epoch 185/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0511 - accuracy: 0.9958 - val_loss: 0.6049 - val_accuracy: 0.8896\n",
            "Epoch 186/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0530 - accuracy: 0.9938 - val_loss: 0.5537 - val_accuracy: 0.9091\n",
            "Epoch 187/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0555 - accuracy: 0.9967 - val_loss: 0.5450 - val_accuracy: 0.8961\n",
            "Epoch 188/500\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0462 - accuracy: 0.9951 - val_loss: 0.5621 - val_accuracy: 0.9026\n",
            "Epoch 189/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0573 - accuracy: 0.9933 - val_loss: 0.5335 - val_accuracy: 0.8961\n",
            "Epoch 190/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0449 - accuracy: 0.9978 - val_loss: 0.5296 - val_accuracy: 0.8961\n",
            "Epoch 191/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0526 - accuracy: 0.9917 - val_loss: 0.5624 - val_accuracy: 0.9026\n",
            "Epoch 192/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0465 - accuracy: 0.9953 - val_loss: 0.5417 - val_accuracy: 0.8961\n",
            "Epoch 193/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0438 - accuracy: 0.9938 - val_loss: 0.5643 - val_accuracy: 0.9026\n",
            "Epoch 194/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0435 - accuracy: 0.9980 - val_loss: 0.6001 - val_accuracy: 0.8961\n",
            "Epoch 195/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0459 - accuracy: 0.9998 - val_loss: 0.5522 - val_accuracy: 0.8961\n",
            "Epoch 196/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0494 - accuracy: 0.9956 - val_loss: 0.5577 - val_accuracy: 0.8961\n",
            "Epoch 197/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0498 - accuracy: 0.9991 - val_loss: 0.5368 - val_accuracy: 0.8961\n",
            "Epoch 198/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0517 - accuracy: 0.9997 - val_loss: 0.5562 - val_accuracy: 0.8961\n",
            "Epoch 199/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0467 - accuracy: 0.9920 - val_loss: 0.5659 - val_accuracy: 0.8961\n",
            "Epoch 200/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8961\n",
            "Epoch 201/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0390 - accuracy: 0.9982 - val_loss: 0.5853 - val_accuracy: 0.9026\n",
            "Epoch 202/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0377 - accuracy: 0.9998 - val_loss: 0.5975 - val_accuracy: 0.9026\n",
            "Epoch 203/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 0.8961\n",
            "Epoch 204/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0318 - accuracy: 0.9985 - val_loss: 0.5809 - val_accuracy: 0.9091\n",
            "Epoch 205/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0482 - accuracy: 0.9881 - val_loss: 0.6003 - val_accuracy: 0.9026\n",
            "Epoch 206/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.9026\n",
            "Epoch 207/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0332 - accuracy: 0.9970 - val_loss: 0.5534 - val_accuracy: 0.8961\n",
            "Epoch 208/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0354 - accuracy: 0.9985 - val_loss: 0.5972 - val_accuracy: 0.9026\n",
            "Epoch 209/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0325 - accuracy: 0.9994 - val_loss: 0.6031 - val_accuracy: 0.8896\n",
            "Epoch 210/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0392 - accuracy: 0.9953 - val_loss: 0.6178 - val_accuracy: 0.9026\n",
            "Epoch 211/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0423 - accuracy: 0.9971 - val_loss: 0.6222 - val_accuracy: 0.8961\n",
            "Epoch 212/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0339 - accuracy: 0.9976 - val_loss: 0.5956 - val_accuracy: 0.8961\n",
            "Epoch 213/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0313 - accuracy: 0.9978 - val_loss: 0.5819 - val_accuracy: 0.8896\n",
            "Epoch 214/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.9026\n",
            "Epoch 215/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8961\n",
            "Epoch 216/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0326 - accuracy: 0.9983 - val_loss: 0.6034 - val_accuracy: 0.8896\n",
            "Epoch 217/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0315 - accuracy: 0.9967 - val_loss: 0.6064 - val_accuracy: 0.8896\n",
            "Epoch 218/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8961\n",
            "Epoch 219/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0282 - accuracy: 0.9986 - val_loss: 0.5824 - val_accuracy: 0.8961\n",
            "Epoch 220/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 0.8961\n",
            "Epoch 221/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0295 - accuracy: 0.9980 - val_loss: 0.6046 - val_accuracy: 0.9026\n",
            "Epoch 222/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.9091\n",
            "Epoch 223/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0261 - accuracy: 0.9997 - val_loss: 0.5899 - val_accuracy: 0.9026\n",
            "Epoch 224/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0286 - accuracy: 0.9995 - val_loss: 0.6301 - val_accuracy: 0.8961\n",
            "Epoch 225/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0238 - accuracy: 0.9996 - val_loss: 0.6147 - val_accuracy: 0.8896\n",
            "Epoch 226/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0206 - accuracy: 0.9998 - val_loss: 0.6458 - val_accuracy: 0.8961\n",
            "Epoch 227/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0239 - accuracy: 0.9960 - val_loss: 0.6177 - val_accuracy: 0.8896\n",
            "Epoch 228/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.8961\n",
            "Epoch 229/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8961\n",
            "Epoch 230/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.6430 - val_accuracy: 0.8961\n",
            "Epoch 231/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.8961\n",
            "Epoch 232/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0230 - accuracy: 0.9994 - val_loss: 0.6389 - val_accuracy: 0.8896\n",
            "Epoch 233/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0253 - accuracy: 0.9995 - val_loss: 0.6312 - val_accuracy: 0.8896\n",
            "Epoch 234/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8896\n",
            "Epoch 235/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0234 - accuracy: 0.9994 - val_loss: 0.6412 - val_accuracy: 0.8896\n",
            "Epoch 236/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.6389 - val_accuracy: 0.8896\n",
            "Epoch 237/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.8961\n",
            "Epoch 238/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8961\n",
            "Epoch 239/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.8896\n",
            "Epoch 240/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 0.9026\n",
            "Epoch 241/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.8961\n",
            "Epoch 242/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8961\n",
            "Epoch 243/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.8896\n",
            "Epoch 244/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.8896\n",
            "Epoch 245/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8961\n",
            "Epoch 246/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.8896\n",
            "Epoch 247/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.8961\n",
            "Epoch 248/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.9091\n",
            "Epoch 249/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.8961\n",
            "Epoch 250/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0170 - accuracy: 0.9981 - val_loss: 0.6583 - val_accuracy: 0.8896\n",
            "Epoch 251/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.8896\n",
            "Epoch 252/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8896\n",
            "Epoch 253/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 0.6489 - val_accuracy: 0.8896\n",
            "Epoch 254/500\n",
            "29/29 [==============================] - 3s 105ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8961\n",
            "Epoch 255/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8896\n",
            "Epoch 256/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.9026\n",
            "Epoch 257/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8896\n",
            "Epoch 258/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8896\n",
            "Epoch 259/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0175 - accuracy: 0.9976 - val_loss: 0.7023 - val_accuracy: 0.8896\n",
            "Epoch 260/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.8896\n",
            "Epoch 261/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8961\n",
            "Epoch 262/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.9026\n",
            "Epoch 263/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.9026\n",
            "Epoch 264/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.9091\n",
            "Epoch 265/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0164 - accuracy: 0.9998 - val_loss: 0.7392 - val_accuracy: 0.8961\n",
            "Epoch 266/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8896\n",
            "Epoch 267/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8961\n",
            "Epoch 268/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.9091\n",
            "Epoch 269/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.9026\n",
            "Epoch 270/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8896\n",
            "Epoch 271/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8961\n",
            "Epoch 272/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8896\n",
            "Epoch 273/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.7135 - val_accuracy: 0.8896\n",
            "Epoch 274/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8896\n",
            "Epoch 275/500\n",
            "29/29 [==============================] - 3s 106ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.9026\n",
            "Epoch 276/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8896\n",
            "Epoch 277/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8896\n",
            "Epoch 278/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8961\n",
            "Epoch 279/500\n",
            "29/29 [==============================] - 3s 107ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8896\n",
            "Epoch 280/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8896\n",
            "Epoch 281/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.8961\n",
            "Epoch 282/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8896\n",
            "Epoch 283/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8961\n",
            "Epoch 284/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.7393 - val_accuracy: 0.8896\n",
            "Epoch 285/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.8961\n",
            "Epoch 286/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8961\n",
            "Epoch 287/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.8961\n",
            "Epoch 288/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.8961\n",
            "Epoch 289/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8896\n",
            "Epoch 290/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.9091\n",
            "Epoch 291/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8961\n",
            "Epoch 292/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8896\n",
            "Epoch 293/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8896\n",
            "Epoch 294/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8961\n",
            "Epoch 295/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.8896\n",
            "Epoch 296/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.7629 - val_accuracy: 0.8896\n",
            "Epoch 297/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8896\n",
            "Epoch 298/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8896\n",
            "Epoch 299/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.9026\n",
            "Epoch 300/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.8896\n",
            "Epoch 301/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.8831\n",
            "Epoch 302/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.8896\n",
            "Epoch 303/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.9026\n",
            "Epoch 304/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.9026\n",
            "Epoch 305/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8961\n",
            "Epoch 306/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.8961\n",
            "Epoch 307/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.8896\n",
            "Epoch 308/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.8961\n",
            "Epoch 309/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.9026\n",
            "Epoch 310/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.8896\n",
            "Epoch 311/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.9026\n",
            "Epoch 312/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.9026\n",
            "Epoch 313/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7768 - val_accuracy: 0.8896\n",
            "Epoch 314/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 0.8896\n",
            "Epoch 315/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.7694 - val_accuracy: 0.8961\n",
            "Epoch 316/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.9026\n",
            "Epoch 317/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7745 - val_accuracy: 0.9026\n",
            "Epoch 318/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8896\n",
            "Epoch 319/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.8896\n",
            "Epoch 320/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.8896\n",
            "Epoch 321/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.9026\n",
            "Epoch 322/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8228 - val_accuracy: 0.8961\n",
            "Epoch 323/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.9026\n",
            "Epoch 324/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.8896\n",
            "Epoch 325/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.8961\n",
            "Epoch 326/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8265 - val_accuracy: 0.8896\n",
            "Epoch 327/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7948 - val_accuracy: 0.8896\n",
            "Epoch 328/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.9026\n",
            "Epoch 329/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.8961\n",
            "Epoch 330/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8961\n",
            "Epoch 331/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.8896\n",
            "Epoch 332/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.9026\n",
            "Epoch 333/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.8961\n",
            "Epoch 334/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.8896\n",
            "Epoch 335/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8961\n",
            "Epoch 336/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.8896\n",
            "Epoch 337/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.8961\n",
            "Epoch 338/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.8896\n",
            "Epoch 339/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.8961\n",
            "Epoch 340/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8795 - val_accuracy: 0.9026\n",
            "Epoch 341/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8669 - val_accuracy: 0.8896\n",
            "Epoch 342/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.8896\n",
            "Epoch 343/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8296 - val_accuracy: 0.8961\n",
            "Epoch 344/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.9026\n",
            "Epoch 345/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.9026\n",
            "Epoch 346/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.9026\n",
            "Epoch 347/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.8961\n",
            "Epoch 348/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8961\n",
            "Epoch 349/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.8896\n",
            "Epoch 350/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.8961\n",
            "Epoch 351/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8425 - val_accuracy: 0.8961\n",
            "Epoch 352/500\n",
            "29/29 [==============================] - 3s 108ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.9091\n",
            "Epoch 353/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8117 - val_accuracy: 0.8961\n",
            "Epoch 354/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8125 - val_accuracy: 0.9026\n",
            "Epoch 355/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.8896\n",
            "Epoch 356/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.8896\n",
            "Epoch 357/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.9026\n",
            "Epoch 358/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.8961\n",
            "Epoch 359/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.8961\n",
            "Epoch 360/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.8961\n",
            "Epoch 361/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.8961\n",
            "Epoch 362/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8850 - val_accuracy: 0.8961\n",
            "Epoch 363/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9079 - val_accuracy: 0.8961\n",
            "Epoch 364/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.9026\n",
            "Epoch 365/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.8831\n",
            "Epoch 366/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9382 - val_accuracy: 0.8896\n",
            "Epoch 367/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.9091\n",
            "Epoch 368/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.9026\n",
            "Epoch 369/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.8896\n",
            "Epoch 370/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.8896\n",
            "Epoch 371/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.8961\n",
            "Epoch 372/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.9026\n",
            "Epoch 373/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.8896\n",
            "Epoch 374/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8655 - val_accuracy: 0.8896\n",
            "Epoch 375/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.9026\n",
            "Epoch 376/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.8961\n",
            "Epoch 377/500\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9481 - val_accuracy: 0.8961\n",
            "Epoch 378/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.9026\n",
            "Epoch 379/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.9026\n",
            "Epoch 380/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.8961\n",
            "Epoch 381/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.8961\n",
            "Epoch 382/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.8896\n",
            "Epoch 383/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.8961\n",
            "Epoch 384/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8961\n",
            "Epoch 385/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9398 - val_accuracy: 0.8896\n",
            "Epoch 386/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.9026\n",
            "Epoch 387/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.8896\n",
            "Epoch 388/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.9026\n",
            "Epoch 389/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.8961\n",
            "Epoch 390/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9809 - val_accuracy: 0.8961\n",
            "Epoch 391/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.8961\n",
            "Epoch 392/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.8961\n",
            "Epoch 393/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8961\n",
            "Epoch 394/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.8961\n",
            "Epoch 395/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.8961\n",
            "Epoch 396/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.9026\n",
            "Epoch 397/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.9026\n",
            "Epoch 398/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.8961\n",
            "Epoch 399/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8961\n",
            "Epoch 400/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9866 - val_accuracy: 0.8961\n",
            "Epoch 401/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 9.5960e-04 - accuracy: 1.0000 - val_loss: 0.9942 - val_accuracy: 0.9026\n",
            "Epoch 402/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.8961\n",
            "Epoch 403/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 8.5822e-04 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.8961\n",
            "Epoch 404/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.9026\n",
            "Epoch 405/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.9026\n",
            "Epoch 406/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 9.6407e-04 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.9026\n",
            "Epoch 407/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0134 - accuracy: 0.9912 - val_loss: 1.0214 - val_accuracy: 0.8961\n",
            "Epoch 408/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 8.0550e-04 - accuracy: 1.0000 - val_loss: 1.0200 - val_accuracy: 0.9026\n",
            "Epoch 409/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 7.0593e-04 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.9026\n",
            "Epoch 410/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 5.7459e-04 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.8961\n",
            "Epoch 411/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 9.4917e-04 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.8961\n",
            "Epoch 412/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 8.7207e-04 - accuracy: 1.0000 - val_loss: 0.9939 - val_accuracy: 0.8961\n",
            "Epoch 413/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 8.8976e-04 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.8961\n",
            "Epoch 414/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 7.3432e-04 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.8961\n",
            "Epoch 415/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0296 - val_accuracy: 0.9026\n",
            "Epoch 416/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 6.8251e-04 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.8961\n",
            "Epoch 417/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 8.5626e-04 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.9026\n",
            "Epoch 418/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.8961\n",
            "Epoch 419/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 7.8611e-04 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.8961\n",
            "Epoch 420/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8961\n",
            "Epoch 421/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.8961\n",
            "Epoch 422/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.8961\n",
            "Epoch 423/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 6.0441e-04 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.9091\n",
            "Epoch 424/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 8.9808e-04 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.9026\n",
            "Epoch 425/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 7.6917e-04 - accuracy: 1.0000 - val_loss: 1.1222 - val_accuracy: 0.8961\n",
            "Epoch 426/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 6.7964e-04 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.8961\n",
            "Epoch 427/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 0.8961\n",
            "Epoch 428/500\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 6.2365e-04 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.8896\n",
            "Epoch 429/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 9.5454e-04 - accuracy: 1.0000 - val_loss: 1.0181 - val_accuracy: 0.9026\n",
            "Epoch 430/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 6.2913e-04 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.8961\n",
            "Epoch 431/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.9873e-04 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.9026\n",
            "Epoch 432/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 6.0552e-04 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.8961\n",
            "Epoch 433/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.5342e-04 - accuracy: 1.0000 - val_loss: 1.0334 - val_accuracy: 0.8961\n",
            "Epoch 434/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.6118e-04 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.8961\n",
            "Epoch 435/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 5.4600e-04 - accuracy: 1.0000 - val_loss: 1.0360 - val_accuracy: 0.8961\n",
            "Epoch 436/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 7.5796e-04 - accuracy: 1.0000 - val_loss: 1.0729 - val_accuracy: 0.8961\n",
            "Epoch 437/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.6995e-04 - accuracy: 1.0000 - val_loss: 1.0688 - val_accuracy: 0.8961\n",
            "Epoch 438/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 7.1329e-04 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.8961\n",
            "Epoch 439/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 5.2423e-04 - accuracy: 1.0000 - val_loss: 1.0661 - val_accuracy: 0.9026\n",
            "Epoch 440/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 6.6057e-04 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.8961\n",
            "Epoch 441/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 4.7525e-04 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.9026\n",
            "Epoch 442/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.2499e-04 - accuracy: 1.0000 - val_loss: 1.0960 - val_accuracy: 0.8961\n",
            "Epoch 443/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 4.7144e-04 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.8961\n",
            "Epoch 444/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 4.0063e-04 - accuracy: 1.0000 - val_loss: 1.1235 - val_accuracy: 0.8961\n",
            "Epoch 445/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 6.5915e-04 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.8961\n",
            "Epoch 446/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 5.1000e-04 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.9091\n",
            "Epoch 447/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 4.9682e-04 - accuracy: 1.0000 - val_loss: 1.0858 - val_accuracy: 0.9026\n",
            "Epoch 448/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 5.6246e-04 - accuracy: 1.0000 - val_loss: 1.1071 - val_accuracy: 0.8961\n",
            "Epoch 449/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 3.9883e-04 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.9091\n",
            "Epoch 450/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.8961\n",
            "Epoch 451/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 3.2231e-04 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.8961\n",
            "Epoch 452/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 6.4553e-04 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.8961\n",
            "Epoch 453/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 2.9004e-04 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 0.9026\n",
            "Epoch 454/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 5.9136e-04 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.8961\n",
            "Epoch 455/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 3.2066e-04 - accuracy: 1.0000 - val_loss: 1.1748 - val_accuracy: 0.8961\n",
            "Epoch 456/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 5.3427e-04 - accuracy: 1.0000 - val_loss: 1.1501 - val_accuracy: 0.9026\n",
            "Epoch 457/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 4.2197e-04 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.8961\n",
            "Epoch 458/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.8961\n",
            "Epoch 459/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 0.0048 - accuracy: 0.9948 - val_loss: 1.1718 - val_accuracy: 0.9091\n",
            "Epoch 460/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 4.0876e-04 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.9026\n",
            "Epoch 461/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 2.7075e-04 - accuracy: 1.0000 - val_loss: 1.1198 - val_accuracy: 0.9026\n",
            "Epoch 462/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 6.4620e-04 - accuracy: 1.0000 - val_loss: 1.1134 - val_accuracy: 0.9026\n",
            "Epoch 463/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 4.2834e-04 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.8961\n",
            "Epoch 464/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 3.6609e-04 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.9026\n",
            "Epoch 465/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 5.1181e-04 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.9026\n",
            "Epoch 466/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 3.0507e-04 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.9026\n",
            "Epoch 467/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 3.6447e-04 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.8961\n",
            "Epoch 468/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1535 - val_accuracy: 0.8961\n",
            "Epoch 469/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 3.6465e-04 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.8961\n",
            "Epoch 470/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.7654e-04 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.8961\n",
            "Epoch 471/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 2.6962e-04 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.9026\n",
            "Epoch 472/500\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 2.9449e-04 - accuracy: 1.0000 - val_loss: 1.1347 - val_accuracy: 0.8961\n",
            "Epoch 473/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 4.4704e-04 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.8961\n",
            "Epoch 474/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 9.9612e-04 - accuracy: 1.0000 - val_loss: 1.1641 - val_accuracy: 0.9026\n",
            "Epoch 475/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 3.0225e-04 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.9026\n",
            "Epoch 476/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.8961\n",
            "Epoch 477/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 2.7252e-04 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.8961\n",
            "Epoch 478/500\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 2.8967e-04 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.9026\n",
            "Epoch 479/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.1311e-04 - accuracy: 1.0000 - val_loss: 1.1906 - val_accuracy: 0.8961\n",
            "Epoch 480/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 3.8673e-04 - accuracy: 1.0000 - val_loss: 1.1687 - val_accuracy: 0.9026\n",
            "Epoch 481/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 3.8707e-04 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.8961\n",
            "Epoch 482/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 3.0836e-04 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.9026\n",
            "Epoch 483/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 1.2005 - val_accuracy: 0.8961\n",
            "Epoch 484/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 3.4819e-04 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.8961\n",
            "Epoch 485/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.2353e-04 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.9026\n",
            "Epoch 486/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 2.2692e-04 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.9091\n",
            "Epoch 487/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.2690e-04 - accuracy: 1.0000 - val_loss: 1.2710 - val_accuracy: 0.9026\n",
            "Epoch 488/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.5091e-04 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.8961\n",
            "Epoch 489/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.2011e-04 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.8961\n",
            "Epoch 490/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 3.4818e-04 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.9026\n",
            "Epoch 491/500\n",
            "29/29 [==============================] - 3s 111ms/step - loss: 1.7365e-04 - accuracy: 1.0000 - val_loss: 1.1905 - val_accuracy: 0.9026\n",
            "Epoch 492/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 1.8506e-04 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.8961\n",
            "Epoch 493/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 2.9120e-04 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.9026\n",
            "Epoch 494/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 1.6913e-04 - accuracy: 1.0000 - val_loss: 1.1815 - val_accuracy: 0.9091\n",
            "Epoch 495/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 2.8451e-04 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 0.8961\n",
            "Epoch 496/500\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 2.6403e-04 - accuracy: 1.0000 - val_loss: 1.1689 - val_accuracy: 0.9091\n",
            "Epoch 497/500\n",
            "29/29 [==============================] - 3s 116ms/step - loss: 1.9288e-04 - accuracy: 1.0000 - val_loss: 1.2450 - val_accuracy: 0.9026\n",
            "Epoch 498/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.0274 - accuracy: 0.9948 - val_loss: 1.1904 - val_accuracy: 0.9026\n",
            "Epoch 499/500\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 2.8364e-04 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.8961\n",
            "Epoch 500/500\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 1.7503e-04 - accuracy: 1.0000 - val_loss: 1.1884 - val_accuracy: 0.9091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "vskc0MPWMMxp",
        "outputId": "8abd2817-b1f5-4aa3-fb58-0642afd78071"
      },
      "source": [
        "# Enable plot in the notebook\n",
        "%pylab inline\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1fnA8e872fedAAk7iKyCIoLivoFa3He0tbbU1lpbl6q/Wqu1trWrda2gVqvWtS5UUXFBrUVkR3bZIWFLIAnZl5nz++PcYWaSSUggk0ky7+d58sydc+/cOTeEeeee5T1ijEEppVTkcoW7AkoppcJLA4FSSkU4DQRKKRXhNBAopVSE00CglFIRTgOBUkpFOA0ESrWSiDwrIr9p5bFbROSMwz2PUh1BA4FSSkU4DQRKKRXhNBCobsVpkrldRL4WkUoReVpEckXkPREpF5GPRCTD7/ipIrJKREpF5FMRGea3b6yILHFe9woQ3+i9zhORZc5r54nI6EOs8/dFZIOI7BORWSLS2ykXEfmriOwRkf0iskJERjr7zhGR1U7dCkXktkP6hSmFBgLVPV0MnAkcAXwLeA/4PyAH+zf/EwAROQJ4Cfips2828B8RiRWRWOAt4HkgE3jNOS/Oa8cCzwA/ALKAJ4FZIhLXloqKyGnA74DLgF7AVuBlZ/dZwEnOdaQ5x+x19j0N/MAYkwKMBD5py/sq5U8DgeqOHjHG7DbGFAL/Bb4yxiw1xtQAbwJjneMuB941xnxojKkH/gQkAMcDE4AY4CFjTL0x5nVgod97TAeeNMZ8ZYxxG2OeA2qd17XF1cAzxpglxpha4C5gooj0B+qBFOBIQIwxa4wxO53X1QPDRSTVGFNijFnSxvdV6gANBKo72u23XR3kebKz3Rv7DRwAY4wH2A7kOfsKTWBWxq1+2/2AW51moVIRKQX6OK9ri8Z1qMB+688zxnwCPAo8BuwRkRkikuocejFwDrBVRD4TkYltfF+lDtBAoCLZDuwHOmDb5LEf5oXATiDPKfPq67e9HXjAGJPu95NojHnpMOuQhG1qKgQwxjxsjDkGGI5tIrrdKV9ojDkf6IFtwnq1je+r1AEaCFQkexU4V0ROF5EY4FZs88484EugAfiJiMSIyEXAeL/XzgRuEJHjnE7dJBE5V0RS2liHl4DrRGSM07/wW2xT1hYROdY5fwxQCdQAHqcP42oRSXOatPYDnsP4PagIp4FARSxjzDpgGvAIUIztWP6WMabOGFMHXAR8B9iH7U94w++1i4DvY5tuSoANzrFtrcNHwC+Bf2PvQgYBVzi7U7EBpwTbfLQX+KOz7xpgi4jsB27A9jUodUhEF6ZRSqnIpncESikV4TQQKKVUhNNAoJRSEU4DgVJKRbjocFegrbKzs03//v3DXQ2llOpSFi9eXGyMyQm2r8sFgv79+7No0aJwV0MppboUEdna3D5tGlJKqQingUAppSKcBgKllIpwXa6PIJj6+noKCgqoqakJd1VCLj4+nvz8fGJiYsJdFaVUN9EtAkFBQQEpKSn079+fwGSR3Ysxhr1791JQUMCAAQPCXR2lVDfRLZqGampqyMrK6tZBAEBEyMrKiog7H6VUx+kWgQDo9kHAK1KuUynVcbpNIFBKqS5t41zYuzEsb62BoB2Ulpby+OOPt/l155xzDqWlpSGokVKqy3n+Anjk6LC8tQaCdtBcIGhoaGjxdbNnzyY9PT1U1VJKqVbpFqOGwu3OO+9k48aNjBkzhpiYGOLj48nIyGDt2rV88803XHDBBWzfvp2amhpuvvlmpk+fDvjSZVRUVDBlyhQmTZrEvHnzyMvL4+233yYhISHMV6aUigTdLhDc959VrN6xv13PObx3Kr/61ohm9//+979n5cqVLFu2jE8//ZRzzz2XlStXHhji+cwzz5CZmUl1dTXHHnssF198MVlZWQHnWL9+PS+99BIzZ87ksssu49///jfTpk1r1+tQSnVSjVeKXPc+pORC77GwYxnEJEDO0JC9fbcLBJ3B+PHjA8b5P/zww7z55psAbN++nfXr1zcJBAMGDGDMmDEAHHPMMWzZsqXD6quUCjN3XeDzly63j/eWwYyTfdsh0u0CQUvf3DEeQCDEQzCTkpIObH/66ad89NFHfPnllyQmJnLKKacEnQcQFxd3YDsqKorq6uqQ1lEp1Yk01Ib17SOns7i6BHYuD8kvPCUlhfLy8qD7ysrKyMjIIDExkbVr1zJ//vx2f3+lVBfn/7nU4Hd3UFfVIW/f7e4ImiVR9tHT8kieQ5GVlcUJJ5zAyJEjSUhIIDc398C+yZMn8/e//51hw4YxdOhQJkyY0O7vr5Tq4tx+gaDGb0j5b3t1yNuHLBCIyDPAecAeY8zIIPuvBu4ABCgHfmiMWR6q+uDyBgJ3SE7/r3/9K2h5XFwc7733XtB93n6A7OxsVq5ceaD8tttua/f6KaU6Mf87guqS4Md43L7PsXYWyqahZ4HJLezfDJxsjBkF3A/MCGFdqPXYS3W760P5Nkop1Trlu2H7ArvtHwgqdgc/fueykFUlZIHAGPM5sK+F/fOMMd7QNx/ID1VdAGrctoPY427/piGllGqzZ8+Fp8+Er56EBr/BIWWFwY+feVrIWjQ6S2fx9UDw9hNARKaLyCIRWVRUVHRIbyCuKDxGQtJHoJRSbbZ3vX187+ew+XNfeVlB86/ZszokVQl7IBCRU7GB4I7mjjHGzDDGjDPGjMvJyTmk93EJuHFpIFBKhd8LlwQ+r/brIC7b3vzrtoVm1GFYA4GIjAaeAs43xuwN8XvRQJQGAqVUeHjcsOSfdnjohg8D9+3f4dsu2dL0tSMvgcyB0BCatUjCNnxURPoCbwDXGGO+CfX7ee8IYkLUxqaUijCVxbDuPRg7rXWTVBc9A7NvCz43wD8QBEtFfeItkNvCZNnDFLI7AhF5CfgSGCoiBSJyvYjcICI3OIfcA2QBj4vIMhFZFKq6ALhEcONCTPsHgkNNQw3w0EMPUVXVMZNGlFLtaNZPYNaPoWgd3JsGc+625bUVEGxQyg5n1E/FLl/ZqMtAXLDfr4N4f7A+gtBmQwjlqKErjTG9jDExxph8Y8zTxpi/G2P+7uz/njEmwxgzxvkZF6q6gG0acuNy0ky0Lw0ESkWg8p320duBO+8R+/i7PHjhoqbH73O+6e/26/Cd9DNIyAgMBP5ik6HXGNssFEIRM7PYJeAJ0R2BfxrqM888kx49evDqq69SW1vLhRdeyH333UdlZSWXXXYZBQUFuN1ufvnLX7J792527NjBqaeeSnZ2NnPnzm33uiml2tHGTyB/PMQlQ6yTU2z7V7793iyimz+zdwZ1FZDS05Z5m38KF9vH696H3OGQmA1VzXSRjrwYpj7c/tfRSPcLBO/dCbtWNCmOwpBaV4PQYKNsW261eo6CKb9vdrd/Guo5c+bw+uuvs2DBAowxTJ06lc8//5yioiJ69+7Nu+++C9gcRGlpafzlL39h7ty5ZGdnt/VKlVIdqawAnr8Qhl8Alz0HdZW2fNuXvmPqKnzbM06xQ0S/867tT6h10uNXFdvH1N72MSkbitcFvtfoy+0IoeN/EpJLaaz7BYIWGCTELW0wZ84c5syZw9ixYwGoqKhg/fr1nHjiidx6663ccccdnHfeeZx44okhrolSql15Uz+sfgs2fOz7hr/za79j/IaBeucJPHtu03MlZkN6X7ud0R+2/i9wf68xcFFIky0E6H6BoJlv7gIUF24nT4qhxwiIjg3J2xtjuOuuu/jBD37QZN+SJUuYPXs2d999N6effjr33HNPSOqglAoB/+abFy7C16rgt6hM5Z6Wz5E5yPYVJGb6RhoFW3Ame8jh1LTNwj6hrCN5vBlI27mfwD8N9dlnn80zzzxDRYW9RSwsLGTPnj3s2LGDxMREpk2bxu23386SJUuavFYp1YlVFjcqME2P2b2q5XMcdwOMuAgm/85XlnNk0+OClYVQ97sjaIHxxr12nkvgn4Z6ypQpXHXVVUycOBGA5ORkXnjhBTZs2MDtt9+Oy+UiJiaGJ554AoDp06czefJkevfurZ3FSnWE0m12YmlrRuJ4PLBgBoy+LHiHbs4wKFrje7767ZbPl5gJl/4jsMw7P+D4n8A8p2M4LaSp15qIrEAgLhvEQzByqHEa6ptvvjng+aBBgzj77LObvO6mm27ipptuavf6KKWa8eixdobur0qbnwjWUAf1VVCwEN6/A4rWQlKQ9Da5w32BIL0fbPio5feOS21alpYPNy+3r3dF2buKEK+i2FhENQ0ZCe2aBEqpLsCbpqFobfPHvHwVPNjPL8mb8Y328ddjmH10RcOEH/rKx30XBp3e9Pj4IIEAbIexCJxxL1z9Wsv1DwENBEqpyBKbbB/9R+pU7oV/nONLAe3NBeRdL0BcUBkk83GOEwiOuwGO/Z6vfMof4Zo3fM+j4+1jsDuCTqDbNA0ZY5CD3E55JBoPgstT1+JxnZkxQTqolFKtF5dix/uX74L3/w92r4TBZ9jAMP9xOPsB37Fr37GPi54Jfq4jzoZr3oQBJ9tmnTPvh28+gCjno/V7n0ByDjx5sr0TiUsO7bUdom5xRxAfH8/evXsP+iHpcgkNREND11ylzBjD3r17iY+PD3dVlOq6vEnfKnbD/MfsLODWOvlOuLfM9zwqBgad5ltC8oSfwHXv+vbnH2PnC0z8kX2ekHl4dQ+RbnFHkJ+fT0FBAQdbtGZfZR376/cRG10Mu6tbPLazio+PJz+/Y0cUKNVtGAN1znDtcr8lIVtqTYhN8b0mvY99PGKK7UhurRNvg+NvDtn8pcPVLQJBTEwMAwYMOOhx985axdGL/8LUtE1wy0HG+yqlup/6al/iSf8soN4OZGN8+YK8UntBcTn0OwGOdGYJX/lS295XpNMGAegmgaC1MhJj2ebOwJTvRDxu3+2cUioy1PpN3vS/I6hwZgTPfwz6Twp8zVWvwPaFcNTlvrIOHt4ZahEVCNITY9hk0m0G0qp9thNHKdW11FVCTZkvaVubXuskhUvrE5j6uXSbb/vlKwNfkzkw5Gmgwy3iAkGxSbNPKvdoIFCqK3r2PNixJLDTtjnGwH3pdpx+3jhfZuKM/oFrA5dsDf76PhMOt7ZdQoQFglhfIKjYE9Kl35RSIbLD5unCmIM30VTts48lWwLXAk7rE3ic/x2B17Vv2+ARAbrF8NHWSk+IoRhnQkewySFKqa6jofbgxzS38pc3BbRXfWXTY/pN6rTj/ttbZAWCxBiKTLp9UnGQdLFKqc6tai+8MR32bWr+GP9F4f1l9D/4+aMip8EkwgJBLPtJxC0xB88brpTq3Fb+G75+BT4Msq7Hvs02cVxzdwQt5fuPT4Oswe1Txy4ickIekBIXjUuEiths0sqa+QNRSnUNJZvtY3y6X9kWmwDu4TEtvza9n2+7z3F23eHRl8OIC+1M4ZCvZdi5RFQgcLmEtIQYdsf2Ja34m3BXRynVVh6Pb3vvRvuYkAHr3oetX8C8R1p3noQM3/aJt9o7hG4+RLQlIWsaEpFnRGSPiKxsZr+IyMMiskFEvhaRo0NVF38ZibFsj+oDxesD/6iUUp2fdwF48A0FddfZANDaIACB7f9JOREdBCC0fQTPApNb2D8FGOL8TAeeCGFdDkhLjGEz+dBQHTiOWCnVOb11I8x71G57F5AHqHaGhtbsDz7q52CGX2DXDeg99vDr2MWFLBAYYz4H9rVwyPnAP401H0gXkV6hqo9XekIMG9097JPSZiaRKKU6j2UvwJxf2O1gy0WunwO7gjQ8JPeEm7+G8dODn/ey5+C8v3a7dBGHIpyjhvIA/6/kBU5ZEyIyXUQWiciig2UYPZiMxFi21Tpjg3UIqVKdwzu3wL1pTcvdDYHPywqaHlNVDJ5629F75cu+8tvWQUY/OOs3dnLYtH+3b527kS4xfNQYM8MYM84YMy4n5/DSQqQlxrC1NtE+qQyy9JxSquMteto+Nl49sPHykI2Hgybn+razBsPQKXbUT2yKrzw6DgaeYhefufRZuLEN6aMjRDhHDRUC/vO8852ykMpOjqOwNh6TEIXoXAKlOt6OZfDlo3Dhk00zANeUQaKzeMvGubDwqcD9ZQUQk2T7BHqMCOw89g4jvbqFb/4jLjz8+ndD4bwjmAVc64wemgCUGWN2hvpN+2QmYnDhTsjWpiGlwuHVa2HFa8EHa1SXOBPBdsLcB3xLRQJUFNlAkJYHP1sN0z8N7DPwDgl1ueyParWQ3RGIyEvAKUC2iBQAvwJiAIwxfwdmA+cAG4Aq4LpQ1cVf30zbLFQVm0mq5htSqmN5PODxtvsH6aStLoWvnoQFTzbd/ydntu/AU20wAJuKeu8Gux2TEIoaR4SQBQJjzJUH2W+AG0P1/s3xBoL9URmkVuw+yNFKqXb17Dm+dn53XdP9NSV+awgbSOrRNB1Mmt+Ykmvegscn2HUGvKuMqTaLuPunjMQYUuKiKXDlwZ61rctgqJQ6dLUV8MQk+OwPsO1LX7n3g7veb/3w6lI7wcvrypfsqB9/qX5rdqf3ges/tNlEB5/R/nWPEBEXCESEHqlxLIsebSeVtWUBaqVU2+1cDrtX2DZ/f/U1Njmcf96vzx6ELf+FoefC9+dC/rjAXEIQeEcAkDscfroCknuEpv4RIOICAUBmUixfeYbZJ/7fUJRSrbPuPVjyfPB9n/4eChb5nu/6OvhxdeU2OdzTZ/rKvDnAUntBnpN1pvGEr7R8VPuK2EBQUB1rMxDuXhXu6ijV9bx0Bcz6cdNyjxs+/R08dbqvzJsTqLF9TvbQ6iAJCFwxvu3aisB9iVltq6s6qAgNBHHsq6yD3JEaCJRqT7XlTctKt0FUbNNy72gfgKg4SHEWox98Jpxyh2/foFPt48VP23QRPXSJ2fYWkYEgKymWkqo6TI/h9o+xXkcbKHVIjAl8HiwQVO2DnCOblhev921nDYbz/mK3pz4cmCY6Z6hdqH7UJXDOHyNq5bCOEpGBIDMpFo+BytRBYDyBi1orpVrvvvTAL1IHZvr6tetX77Mf5o3t9QsEfcbb9BD3ltm5AapDRWQgyEq2t6kl8U6nU0trniqlArV0F1DjBAJXtO/Yqr32wz0mKfB13i9gY6+Bs+4PSVVV60RkIMhNjQdgG07CqpevtNPXlVIHV1fR/HPvHYGn3mYTvS/DThxLzIK4FJroNwnOfzT4PtVhIjIQDOuZCsCKvX6Xv2lumGqjVBdTXRr4/OmzfHm7avY3Oti5e0jIDGz398rVjt/OICIDQVpiDL3T4lmzqxyO/rYtDLbghVKRrqbMftDvXu1X1igQVO7xZQmtLQt+nsSs4IGg58j2qac6LBEZCACO7JXKul3l8K2/QXRC0zznSik7smf7V7D8X76yxncEAFHOuP8mdwSOxGbuCLKDdCKrDhexgaBvZiLb91XZG9fU3oHT3JVSlvdDf/1HvrLGawSAb55AbTOBIGsIJKQHKR90ePVT7SJiA0F+RgKVdW5Kq+ptINi/I9xVUqpjLZgJBYub37/0BXjxYrtdtAZKt9ulI9fNhj7HBR7rnQnsv7j8WX65hZKyfHMJLpzhK9dZwp1CRAcCgMLSakjN00CgIsvmz2H2bfDUac0fs/i5wOfr50DpVjsKqO/EwH3elNL+Q7ET0uH8x2zyOICJN9rZwaMu9R2jC8d3ChE7RS8/w65LUFBSxcjU3lC+wy6aoSsbqe6ucAk8962DH+e/jGRqHqx9F1J62eeNR/vUV9nHvRt9ZTEJMPLiwPONusRup/W1qaNVpxDBgcDeEWzZW2WbhjwNUFkEKbkHeaVSXVxz7fiNufw+HkZdatcZ7jXaPh9wsu389TYF1VXaJHL+gy6C5Rfy+lkziehUWETs19/0xFjy0hNYUVhmv+2AjhxSkcF4Wnec/x3BwFPsl6V179n1AVJy4Y4tvv11lfCvywJf31IgUJ1KxAYCgNH5aXxdUOrLbaKBQHUXGz6Cf5xj00I3FiwxXDDuBt929hD7WLQWUnoGOed+2yzUcxRc975tQmrcoaw6rYgOBCPz0ti+r5qKOGdpvFemBY56UKqrev27sPV/NvNnY60NBP7rBKT45QryDwQXOUNJd60A44YJN0K/iXDr2uDDRVWnFNGBoI+zkH1hXbJvGNv2BWGskVLtxNssE+yLTeNAsG2+L4PoV0/aHEF1lb4gEhVrB1F4x/wn+wWC0ZdC/njfymI9hrXfNagOE9GBIC/dJp/bsb/WrnkqUbqGseqaqvbZD/D1H9rn3kAQLHVK40DwzNnwiZP984uH7OOCmVCxC46+Fm5z0kXnHWMfEzMDXx+b6HvPYOsOqE4vpIFARCaLyDoR2SAidwbZ31dE5orIUhH5WkTOCWV9GuuVZkcO7Sytgdgk+21mZzPrqyrVmXnXBf7f3+yjN+VDsGUgvaOGEvw+0L3j/73j+r3nOeY6XxOPt82/8V2Gt8kobxzExB9a/VVYhSwQiEgU8BgwBRgOXCkiwxsddjfwqjFmLHAF8Hio6hNMj5Q4XAI7y6ptQUpPm0BLqa7Gu0aA94PcO9M36B1BBST1gDN/7StzRQWuM1C9z6aI9i4gDzDiAjjqSjjxtsDzxafZx/6TDu8aVNiEch7BeGCDMWYTgIi8DJwP+KUxxACpznYa0KHTe6OjXPRMjWf7PmcyTGI2FH3TkVVQqn0cGBLqBIIDTUPNdBbHpUBanq9szX/g3VsCg0Fyj8DXxSTAhX9ver5T7rDDS4889xArr8ItlE1DecB2v+cFTpm/e4FpIlIAzAZuCmF9ghrbL4MvNhTj9hhIyoaq4o6uglKHr6HRutseZ+jnR7+CuqrAfTWlNhAMPBV+ttqXAXTRM4FNScmtnFyZ0R+Ouhzikg+p6ir8wt1ZfCXwrDEmHzgHeF5EmtRJRKaLyCIRWVRU1L4riZ0zshfFFXUs3LLPjhyqr2r6H0epzmrfZpsZtNZZJayh1mYH9Z89vG2eb3vXCjvHIKWXbUZKy4Njv+fb7x9QGt8RqG4rlIGgEOjj9zzfKfN3PfAqgDHmSyAeyG58ImPMDGPMOGPMuJycnHat5ClDc4iPcfHeip32jgDgswfb9T2UCplnz7UZQr0duNvnw7u3QvlO3zFVJVC6zW5v+sw+nna3b/9x0+EHn/uee7+LxSSGrt6qUwllIFgIDBGRASISi+0MntXomG3A6QAiMgwbCDp08eCkuGhOGpLDx2v32D4CgP89FHxGplKdTcVu+1gYJJ30mGn28Y3vwUOj7N1AwQK7EFPjpHFpft/ZvJ3B2YPbv76qUwpZIDDGNAA/Bj4A1mBHB60SkV+LyFTnsFuB74vIcuAl4DvG+PdWdYyj+qRTUFJNtSvBV6hpqVVXkDHAPm6d13RfWn7g879PgtVv29FxjdM/+68edvQ1cOs6GHxG+9ZVdVohzT5qjJmN7QT2L7vHb3s1cEIo69AaQ3rYTq71sSMY3dP55lSyBdL7tPxCpcKlpgw2fmLb8feuh/0FTY8JlhMIgt/t+geG5J4QrQnjIkm4O4s7hSG5KQCsK66Fy1+whZs/C2ONVER7/y47S7gln/8JXvuOzSfUHP/O3t5jfduVB2l91SAQcTQQAH0yEoiNdrFhTwWkOrfTn/8RdiwLb8VUZJrvzKv0uG3Khz8MAnd94DHeFcEAeh9NUEl+Ayv8Rwb1bSYr6HkPwQk3t72+qsuL2IVp/EVHuRiYncT6PRUQFQ2XPQ+vXmP/Q1404+AnUOpgaitsGpO2LM1YXWLnAYD9UhKbCJmDbBqHmjLfcT1HwY4lTV+f5DcA74jJcOd2p8mzmZXBxl3X+rqpbkXvCBxH5Kawfo+TjGv4VDjuBlj5BmxfCDWtXNFJqWBKt8Hv8mDub21zTrA00Hs3Bs7qBXjfLz3XqjfhiePhvdvtc//hofGpEJvS9Jz+dwQJmfa4XqM1PbRqQgOBY0iPZLbvq6ay1pmRecx14KmHp89o3fquSjWnZKt9/PwP9gN91VuB+7f8Dx45GmbdBI8f7ytf8RoMPcfeBSz5py3zZhct3+U7LiYRbl9v5wKc8ydfeazfTF9di1u1QJuGHCPzbOfc1wVlTByU5VuRCWCn9hWow+Bq9N+s8eT5vU6a56XPN33t4DMAgX3OovDiLB/pHwgaamweoF5H2Z/ZzjwAEbjuPSjdjlIt0a8JjqP7ZSCCTTUBgeu1KnU46hulLGmoDnzuzRQaTL/jA7+UVO6B/TttviDvwAZvegmvwWf6+gH6HW/zACnVAg0EjrSEGIbmpvgCQWPv3gp71nZspVT3UNfog7qiyK4ABnb9i7d/1PxrMwfZvEAAcal2tNCsH9vnoy6xj43nC0x73S60pFQraSDwc2z/TJZsLaHB7aT0Fb+7goVPwZvTw1Mx1bUsmOlb6AV8H/pen/0eftvblr94aeA+/xm+YMf0D58KR0yBGxdAvxNs0jiAU+6Ey1+EST9r/2tQEUUDgZ9jB2RSWedm9U5nlND3PoSoON8BpdubjuxQyl9dpW2jf/Y8+7dyb1rg6B9/v+1tl4P0N/qKpsel9oarXobUXnDVK3DCT+G0X9p+gWHn+VYjU+oQaSDwc3RfO6xu+fZSW5B3DJz9gO+A6n2B6X2VAjsSaL6zYIs3C+j+Qt+2/5j/gzn6Wl+fwZHnNd0flwJn3gcn3dZ0n1KHSAOBn7z0BNITY1i1w+/DPtVZS8ebgOv3fe3cAqW8XvsOvH+H3a4u9ZV7Uz/782YETc1vug8gd7gdCvp/O+HS59q1mko1R4eP+hERRvRO5dN1RdQ2uImLjoKhU+DHi6F0q69tdu4DdqH7sx7Q8dkqkP/C7v6BIDYZblljv9FP/JFdFez+rMDX3uMMVGjcT6BUiOmnWCNnDMtl1/4aHpvrHbctNi+7fwKvTXNt+gn/DkGl3PXNB4K4FDuzV8SuBRAVDWfcZzuBvXTIsgqTVt0RiMjNwD+AcuApYCxwpzFmTgjrFhbXnTCAlxdsZ+HmRsNIk4Is21e+QxfviHT+gwfevxOKv/E9L/Ibbhyb1PS1k35qH798LPjfl1IdpLV3BN81xuwHzgIygGuA34esVmF2TP8MVhaWEbBGTmJW0wN1xmb3Vl0KHgxRt6kAACAASURBVE/T8rICeOtGO0LIf47Awqdgs9+Sj/4zhWP8Fj1qbOKNMPrS5vcrFWKtDQTelInnAM8bY1b5lXU7Y/qkU17bwP3vrPEVRgW5eSrTQNBtVZfCg/1sfiCvz/9kE8etfhuWvQDffODLAdScASfbx5ZmDysVZq0NBItFZA42EHwgIilAkK9K3cNFY/OYNDibfy3YSlVdg2/HGffahWuufRui4/WOoDsq2WLXAfAu+LLoGV/5J/fDZw/Cf/9sy755Hz74v5bP5x3mOeXBUNRWqXbR2lFD1wNjgE3GmCoRyQS6bfLy6CgXN546mCtnzufzb4qZPNKZwu8/g7PvRNg2z7YRtyXHvOq89u+Avx0Fk27x5QdyRdulS5/yW7+3aq99/PqVwNdLFFw8E4o3QI8jbb/AgJPgnhIdXaY6tdb+dU4E1hljSkVkGnA30IZZMl3PMf0yiI1ysXRbSfADRl5sRw3tWNqxFVOh4x3ls262zQEEdmLY3yfZDJ9jp9l8P2BzAHld+zaMuBCun2P/Lk65A4af75t7okFAdXKt/Qt9AqgSkaOAW4GNwEEaR7u22GgXw3ql8HVBM/HuiLPtY0trxqquo3QbPOP8m3oa7OifIyb79o//AUz5g29m+Zm/hvg0mxCu3yS49FnIH9fh1VaqPbQ2EDQYO4TmfOBRY8xjQJAlkbqXUflprCwsw+MJkl8ouQek9bWdhSVbbWbSZS91fCVV61Ttg8/+EJgAbsdSW+7xwPwnfOUVRVBVDP0nwdX/hkv+Ydv4Y5NgmLNI0RFnw8+32CyfwQYSKNWFtPYvuFxE7sIOGz1RRFzAQYdBiMhk4G9AFPCUMabJkFMRuQy4FzDAcmPMVa2sU8iNzk/nhfnb2Ly3kkE5yU0PyB8Hq96Ah8eAcfrO182Gi2badWVV5/HMZCheBzlH2myeNfthxikw6HRI7wOLn/UdW+vcBWYPhSFnBJ7nopk2d9CBRG/a7KO6vtb+FV8O1GLnE+wC8oE/tvQCEYkCHgOmAMOBK0VkeKNjhgB3AScYY0YAP21b9UNrdL531bLS4Aecfg+cfKcvCACsmQXbvuyA2qlWqy6xQQB8s8G3/Nc+7lkTGASi4uDY79l/1wEnNT1XTELT/P9KdXGtCgTOh/+LQJqInAfUGGMO1kcwHthgjNlkjKkDXsY2Lfn7PvCYMabEeZ89bap9iA3OSSYhJorl25vpJ8gcAKfeBVlDbBKx/ifa8qJ1HVfJSFFfDc9NhcIlgeXuBmioDf6amv3QUAebPvOV7d0A9TXwyW/s87hGLZy/3APn/tn+u+pdnYoQrU0xcRn2DuBT7ESyR0TkdmPM6y28LA/wH2hfABzX6JgjnPP/D9t8dK8x5v3WVT30oqNcHNUnjcVbSzDGIM0NE73sn3YIac6R8IeBsGd1x1Y0EuzdAJs/g63zIO9oX/m/LoWNn8C9fsF6yT/tXIB5D9tUzus/tFlkU3rZO4LCRb5/o2IN2kq1tmnoF8CxxphvG2OuxX7b/2U7vH80MAQ4BbgSmCki6Y0PEpHpIrJIRBYVFRW1w9u23rh+mawoLOOCx/4XvNMYbOrgHsNsMOgxHHZ93aF1jAhlBfbRO4bfa+Mn9tGbDsTdALNugnd+aj/0N34CRWvsHJCeI+2cgJIt9tghZ3VI1ZXq7FobCFyNmm32tuK1hUAfv+f5Tpm/AmCWMabeGLMZ+AYbGAIYY2YYY8YZY8bl5OS0ssrt46wRuQAsLyjjwzW7D/6CASfCjmVQWRzimkWY5gKBl3c00Pb5geW7V9rHtHwYdJod/ultFso7xndcah5M7rbps5RqUWsDwfsi8oGIfEdEvgO8C8w+yGsWAkNEZICIxAJXALMaHfMW9m4AEcnGNhV1qtzOo/PT2fjbc4iPcbGgcUbSYI44GzCw/OWQ1y2ieANBdTP/BlVO4N25PPj+pB4w8BS7Xb7TPmb7fef4yTKY8MPDraVSXVJrO4tvB2YAo52fGcaYOw7ymgbgx8AHwBrgVWPMKhH5tYhMdQ77ANgrIquBucDtxphmvvKFT5RLGNozldU7WrFMZa8xdkji3Ad8q1V53MGzWKrW2+/cTFb5BYLact92pfNns3dD8Ncn59gJYN/x+/7S8yjfdnRs+9RTqS6o1TNhjDH/Bv7dlpMbY2bT6M7BGHOP37YBbnF+OrXhvVJ59+sd1DV4iI1uIX6KwGm/gJmnwT/Ph2O+Y4NC34m+TmUV3Lb5to8lPrVpDif/pqHSbZDcE7b4zequKoaV//YliQObDsI7E9ib77//CfYxbxxkDgzdtSjVhbQYCESkHDvRq8ku7Od4akhq1QmdNSKXlxZs488fruOuKcNaPrj30ZA7CnYus52WKb3t/IKvnrSrUEXHwahLW85RH2nqKm2Kh4Gn2nH6y18KHAlU5twRFK2Fh0bZ3+/uFb79H//a1x+QmGU7jY+5FuY9Ysv8h4LeVWiTyblckH2EL3+QUhGqxUBgjOn2aSRa69ShPThzeC5vL93BnZOPbH4oKdhvst//BH7jdGxf9TLM+olvgXOwI1dOvyfoyyPK5v/a4aDeJR63L4B6p+P3jR/YNM7F3zhNQ8KB7yX+QQB8QQCBC56wI4I8bl8g8BfnN0v8xgV6l6Yins6Pb4Ozhtv1jG99rZkOSX/+bc65o+CKf0Hvsb6yilaMQOruSrfDc+fB69fbD30A4/bt//pleHQcvHyVLR9xQfDz+P9eb15uO+xFbA6gaW/YXEHN0SCglAaCtjh/TB5TRvbkjSWFLNrSihFEP/oKvvuBbYJIy4Pvfezbt/4j2PqlbddubmZsd1JX1bTMO9Lnm/dg6xd227TQqX7UVXaCWGPXf+TbTu8buG/w6TDyorbVVakIo4GgDWKjXfzlsjGkxEfz0oJWrE7W40joO8H33BVl7w4AKnbBPybD699t+1DTwsV2hm1LjAlcWL2t3rkF/tNOqZ9KtsJve8FXM3xlW7+0Sd8ac9c1f56cI+CKF305gHqPhZ8std/8o+Ntmg/9hq9Um2n+3DZKiI3izOG5fLh6F7UNI4mLjmrbCX74BSyYCbNv85XtXAZ8u3Wv97jtiCSAO7bYkTNHntv0A3D27XYFrbu227uOIWc1zavTnLoqWPS03RaBnqNh3GEsSOfNvfTe7TalQ/9Jdt3f1ohOgKtegZ6jIDHTlo261C4SP+JC38if2zeA6PcapQ6FBoJDcMGYPN5YUsj7K3dx/pi8tp9g/Pdh+AWw+B+wfo5Ne9Bam/0SqP11FNSV27Hx3mGRYO8EFs50jv/c3nWMuRoueLx177HRrwlryfN2Bu7Xr9pUDWf/DsZc2brzfPFX+4E/5mpf2cKn7E9rTHvDjiJqvMLX0ddC7kib28mrtUFOKdWEfoU6BJMGZ9M3M5EX52879JMk58DJP7fj2Xet8KVHBjv57J2fwfaF9nl9tW9C2u5VvuPqnAlVJZsDz71njW+7wDnHvs3w8tXw6LEHr5v/+HxPvT3Htnl2ZM/c3wYe6/HYpqp5j8C9aTZ9g3fS19zf2sVfPj2E1A1TH7Ht+80t85h3NMQmtv28SqkmNBAcApdLuOq4vizYso9XF26ntKqFdu2DOW66bd/+1xW+fDlbv7ATo56/AMp3wQM9bbNKXRXs3dj0HGvftamVvfwzanr7ElxRsPYdOxTTX10lvPUju3D7mnfgzRuaLsruP5LH+8G8c7kNYPP+Zpuq5txtyz//I/xjiu0P8Lb3VzXKuzTqsuZ/Hyf81K4BPGZa88copdqVmMPpUAyDcePGmUWLFoW7GhSV13LsA3a0yolDsnn++sYZtttg4yfw/IV2O70flG5t+fiMAXbG7Ljv2g9egH4nwHWzbUD430Pw6e9seVQcuGvtfu/6yr/Y5ZvMtnGuDTjDvgVr/uN7j2D1GHS6bWq6ew/8OqNt15g1BPaut9s3LYENH9s7mo9/bcsm/MgGvUtbGOqplDpkIrLYGBN0YW3tIzhEOSlxB7bnbzrM9EiDTrM/W+fZtu+DBYK4FDtaRsQXCLb+z6Zh+OsI+zytL9RV+JK0bfVr7vnTUDvW/uKZviYp/yAA0Oc4W4/Mgb5j8o+1/QcP9mu5fgNOstfiaYDkXDtnovdYm/Rt6GTIGmR/wK4Gtmct9D2MQKqUOiwaCA7DjGuOYfrzi6l3GwpLq8lLP4yUEZe/aJtg4lJsc01dpc1RVLze9yE+/ALfB6p3lNCwqTZ9BfiCANihlp4G2PRp0/eqLYMVr8KFTwb2L2QM8D3vM94e0+8EO8+hYrcduQO+/D09hjddhKfXUfBtJ6iUbrd3JstehGHnwfDGC9RhE8FpEFAqrLSP4DCcNaInX9xxKlEu4Z/zthzeyWITfSNfYpMguQd862+2uefGhfYD/4LHYdJPofcY3+sufQ5uD9Jv0H8SJGbb7ZEXQ1qfpsfM/Y3t5PUOu/R+0IMNAK4YexeQO8Ku7tVnfOAs3uNuCDzf+OmB2T3T+8Apd9n1f4ee2/rfhVKqQ+kdwWHKz0hk0uBs5qzezfSTBpKVHHfwF7VVzhFw+fPB97lckJTdtLzfCbZdfuXrcNLPIWeoHU30xETfMf/9s30cfQXsL7D9BEk5dg5Bj2Hw4wW2ryDvGKgsssFp+qd2sff/3AxDzgx8z0GnB+bxARsMTr3rEC9cKdURtLO4Hfxlzjoe/sTmwV/3m8ltn2TWHgqXwMxT7fYlz8CIi2zzUX1NYObNe9Ps4/mPwds32kydt623o4rADgd11x184XbveXevts1PDdUw6Rad2atUJ6WdxSE2tKcvjfH8Tfs4+YiOXU4TsOPqb1wIZdtg8Bm+8sYf6Oc/bkfqjLrU3iGMvMgXBMDeYbgOEgT8z5s73P4opbos7SNoBxMGZpKRGAPAu1/vCF9Fco4IDALBjL0abltn10Q4+4HAdXuVUhFJA0E7yEqOY+k9Z3Hl+D7MWr7j8CaYKaVUB9NA0I6umdCfmnoP335mAXe/tYKu1v+ilIpMGgja0fDeqRw/KIvlBWW8MH8b+yr1zkAp1flpIGhnT15zDOeP6Q3Alr2VYa6NUkodnAaCdpYSH8NPTh8CwA9fWEJVXUOYa6SUUi3TQBACfTJseuQ95bV8uFrXJlZKdW4hDQQiMllE1onIBhG5s4XjLhYRIyJBJzt0NbHRLob0sDNsV+3YH+baKKVUy0IWCEQkCngMmAIMB64UkSYzj0QkBbgZ+CpUdQmHOT87iaPy05jx+SZemH+QbKJKKRVGobwjGA9sMMZsMsbUAS8DQdJPcj/wIFATZF+XJSL88JTBDO6RzN1vrWRTUUW4q6SUUkGFMhDkAdv9nhc4ZQeIyNFAH2PMuy2dSESmi8giEVlUVFTU/jUNkckje/Li947DJfDW0sJwV0cppYIKW2exiLiAvwC3HuxYY8wMY8w4Y8y4nJww5PE5DLmp8ZwwOJuHP9nALa8sC3d1lFKqiVAGgkLAPwl+vlPmlQKMBD4VkS3ABGBWd+kw9nfBGHsj9MbSQjYX69wCpVTnEspAsBAYIiIDRCQWuAKY5d1pjCkzxmQbY/obY/oD84GpxpjOlWO6HUwd05ufnXEEAC8v3Bbm2iilVKCQpaE2xjSIyI+BD4Ao4BljzCoR+TWwyBgzq+UzdB8xUS5uPmMIm4srePKzTVTVurlv6ghcLs3dr5QKv5CuR2CMmQ3MblR2TzPHnhLKunQGv/rWCFwiPD9/KwOyk/jupAHhrpJSSunCNB0pIymWP192FMWVdfz+/bUM6pEcnkVslFLKj6aY6GAiwkOXjyEjMYZbX13OysKycFdJKRXhNBCEQWZSLGcMy6W4opbzHvmCylpNTKeUCh8NBGEybUI/YqPtr3/W8jAub6mUingaCMJkWK9U1t0/mdzUOD5eswePR1czU0qFhwaCMBIRThiUzUdrdnPDC4uZ+ugXzNtYHO5qKaUijI4aCrMfnTqILXsrmeOsWzDz800cPyg7zLVSSkUSvSMIs8E9Unj9huOZepRd3nLuuiJWFOhIIqVUx9FA0Am4XMLDV47l+EFZAHzr0S+Ys2pXmGullIoUGgg6kV5pCQe2pz+/WNc7Vkp1CA0Encg95w3nV9/yLeL22bqus/aCUqrr0kDQiaQlxnDdCQPY8MAUMpNieXfFTgpKqsJdLaVUN6eBoBOKjnJx9ohc3vl6J5MenMtz87aEu0pKqW5Mh492UtdPGojbY9hUVMmD76/lgrF5pCXEhLtaSqluSO8IOqnBPZL5wyVHce/UEVTVufnznHX8dvYadpRWh7tqSqluRu8IOrmReWmcPSKXf365FYA1O/fz3HXjdVEbpVS70TuCLuDBi0fzmwtGcsfkI/nv+mL+9vH6cFdJKdWN6B1BF5CeGMu0Cf0wxrBhTwV/+3g9n35TxJ8uGc2Q3JRwV08p1cXpHUEXIiI8cOFIBmYnsXx7KVfO/Ir9NfXhrpZSqovTQNDFxMdE8eoNE/n7tKMprqhl5uebwl0lpVQXp01DXVB2chyTR/bi3NG9eOSTDSzaUsIZw3M57cgeDMhOCnf1lFJdjN4RdGF3nH0kJwzOYtu+Ku5/ZzXXPP0V5dpUpJRqo5AGAhGZLCLrRGSDiNwZZP8tIrJaRL4WkY9FpF8o69Pd9M1K5MXvTeCT207m/vNHsKO0mkue+JI3lhTg1hXPlFKtFLJAICJRwGPAFGA4cKWIDG902FJgnDFmNPA68IdQ1ac7i4uO4pqJ/fnFucNZt7ucW15dzp/nrAt3tZRSXUQo7wjGAxuMMZuMMXXAy8D5/gcYY+YaY7xZ1eYD+SGsT7d3wZjeB7ZfX1xAVV0DX27cizF6d6CUal4oA0EesN3veYFT1pzrgfeC7RCR6SKySEQWFRVpaubmZCXHMednJ3Hf1BHsKa9l+D0fcOXM+bzw1bZwV00p1Yl1ilFDIjINGAecHGy/MWYGMANg3Lhx+vW2BUfkppCRGMvM/24iLtpFemIsv3lnNTEu4ZShPeiZFh/uKiqlOplQBoJCoI/f83ynLICInAH8AjjZGFMbwvpEjJyUOL644zQAisprOekPc7nzjRWIwIDsJK6fNIBzRvYiIyk2zDVVSnUGoWwaWggMEZEBIhILXAHM8j9ARMYCTwJTjTF7QliXiJWTEsfz148nPyMBY2BTUSW/eHMlY+//kH2VdeGunlKqEwhZIDDGNAA/Bj4A1gCvGmNWicivRWSqc9gfgWTgNRFZJiKzmjmdOgzj+mfyxR2n8eHPTgoov+ftldTUu8NUK6VUZyFdbUTJuHHjzKJFi8JdjS7r+flb+eVbK5k2oS8vzN9Gz9R4bjp9MFcfp1M4lOrORGSxMWZc0H0aCCKPMQYRYc6qXUx/fjEAZ4/I5azhPbno6DxEdK0DpbqblgKBppiIQN4P+rNG9OSF648D4INVu7n1teX8SSeiKRVxOsXwURU+k4Zk885NkxjaM4V73l7FY3M3UlReyxG5KSTFRXPpMflER+n3BaW6Mw0EipF5aQDcf/4IdpVV8+qiggP7Hv1kA7efPZThvVMZkJ1EjAYFpbod7SNQATwew+qd+1m7q5x//G8zq3bsP7Dv+kkDGJqbwsRBWfTJTAxjLZVSbdVSH4HeEagALpcwMi+NkXlpHDcgk4/W7CYrOY6fvLSUp7/YDEBKXDQvTZ9w4E5CKdW16R2BapXt+6p44N01pCXE8N7KnVTUNnD5sX35+dlDdYayUl2ADh9V7aqovJbfzV7DG0sLGZidxLH9M+mTmcCkITmMyksjyqXDT5XqbDQQqJB4bt4W/vjBOipqGw6UnTgkm5nXjqOm3k1cdBQJsVFhrKFSyksDgQoZYwybiiuZ9tRX9EiN5+uCUob0SGZHaQ3ZybG88oOJ5KZqxlOlwk0DgQo572zld7/eyaNzN7B7fw37KutIS4hhdH4ag3skc/PpQ6ht8BAT5SJT+xWU6lAaCFRYvLW0kNtfX05qfAx7/TKdjspL43cXjWJwj2TiY7TpSKmOoIFAhU1xRS3pCTE8+fkm3lpaSElVHcUVNihkJMbwxLRjmDAwK8y1VKr700CgOo3d+2u46PF5nHRENp9/U0xhaTVH900nLyOR4b1S6ZESR9+sRI7smUJKfEy4q6tUt6GBQHUq3v6EPftreG1xATM+30RZdX3AMfExLm458wiMgYuPySc7OS5MtVWqe9BAoDo1j8ewasd+Nu+tZGTvVNbsLOenryyl3m3/NrOTY+mbmciwXqlcNq4PibFR7K9p4Jh+GWGuuVJdhwYC1eVsLq5k3a5yNhdX8ubSAr7ZXQGACHj/ZI/ITWZ4r1TOGJ7Lsf0zdZiqUi3QQKC6vPKaekqr6nl+/la+3LiXFYVlTY45smcKw3qlMrZvOkNzU8hMimVgTjJgm6OiXKKL7qiIpYFAdTubiyvZVVbDf9cX8finG0lPjKG0qr7JccN7pbKhqIK6Bg/j+2fy88lDGdc/kwa3hwaP0eGrKmJoIFARoaSyjj98sI4RvVOpqXezesd+3lhaSEZiDCV+QSIlLprqejcNHsMZw3IB28wUFx3Fdyf1xyWCCCTEROkdhOo2NBCoiFVYWk3vtHhEhJLKOt5ZsZNHP1nP7v21B47pk5nA9n3VAOSlJ1BSVYfHGDweyEmJIyU+mjOG5ZIYF8XV4/uRFBeFS4SqejflNfX0Sks4cC7viKjm1Ls9uriPCgsNBEr5qal3E+USPl6zhyN7ptA/O4l6t4cvN+7lrx99Q3JcNHnpCRSUVFNSVYcxsHqnb4Eel0BstIt6t8HtMSTGRjG8Vyq90xNYur2EugYPV47vizFwdL8MMhNjKa+tp6i8ll+8uZKZ145j4iCdRKc6VtgCgYhMBv4GRAFPGWN+32h/HPBP4BhgL3C5MWZLS+fUQKDCYX9NPWt27GfuuiJKKutIjo8mPsZFYmw0O8uqWb+7wrn7SGBvZS0biyqbPZdLYETvNAyGovJaauo99M20E+oS46KobfCQGBPF106H+NSjejMgO4mU+GgSYqLYUVbDwOwkCkurGdwjmcraBlLjY4iNdpEUp2tNdTe1DW5mfr6Jayb0Jy3x0CdZhmWFMhGJAh4DzgQKgIUiMssYs9rvsOuBEmPMYBG5AngQuDxUdVLqUKXGx3DcwCyOa0U6jJp6N9/sLqdXWgLrdpVTXe9GgKXbSxjSI4U1O/ezckcZDW7DgAHJlFbVUVPv5t0VdsGfuGgXtQ2eA+dbsHlfq+oY7RL6Ziayr6qOaJeQmhBDUmw0VXU2TXivtAR6psVTU+8mLcEGjrKqerxfBdMSYnB7DGkJMURHCXHRUcRGu0iOi6LOqU9mUhyVtQ2kJcYQ5TSPxUW7cHsMxtg5Hw0eQ0p8tHO3FE1stAtjDDX1HqJcQnJ8NDFRwZvPokQoKKmmX1YiibHRiIAAbuf1SbFRB9a7EBGMMdS7DQ9/vJ59VXU8cMHIZpvm/JvtjDHUuT3ERbfPYIHymnoSYqKI9mv2M8bQ4DGH3RT41tJC/jTnG4or6rh36ojDrWpQIbsjEJGJwL3GmLOd53cBGGN+53fMB84xX4pINLALyDEtVErvCFR3Ve/2UFPvJiEmijq3h4SYKCpqG1hRUEZNgxu3B6rqGoiLjmJPeQ09U+NZvLWErORY9lc3UO/2sG1fFVnJsdQ3GMqq66ltcJMQG0VZdT1b91bhcUZKFVfUYgykJsRQVFFrPyQRPM6HV1cQ7bL19a9uanx0QCDwBop6Z5RYtEuIjbYfzLUNHlLjo53BAQJOSDTGbgkQ5ZIDH+T2vWzAc4ngEg68186yalLiY0h27sjq3B4qaxtocBt6pcfjrVFtg4faBg/p3m/2rfhVF1fUsr/GBvO7zx3G904ceEi/r3CtWZwHbPd7XgAc19wxxpgGESkDsoBi/4NEZDowHaBv376hqq9SYRUT5TrwoeP9ZpkSH8Pxg7Obfc1ZI3q2y3v7f/eqqfcgAnsr64iLdh1YZKiqroH91Q2kJcSwr6qOereHlPhoauo9xMe4qG8wlNfUE+US9tc0EO0Squrc1NS7qXN7SI6z3/ArahqaDTa1DR5cAtX1boyxs84NtjktPiaKqjr3gde6PR4EIT7GRU5KHPsq69m9v6bJOWOi7Id/lMuF2+OhrsEGhbjoKCprGzAY3B4O3H2Ab+Ki22MDiYitg+vAHQUHgpDBBtf6Bg9uJ6DGRgvxMVEYAyVVvsy7USJER9nfCwfe6+Aj03KS49hTXkNOSmhSrXSJBkVjzAxgBtg7gjBXR6lux//DyLuqXF56QqOjfB9CfbMSO6JaqoOEchxbIdDH73m+Uxb0GKdpKA3baayUUqqDhDIQLASGiMgAEYkFrgBmNTpmFvBtZ/sS4JOW+geUUkq1v5A1DTlt/j8GPsAOH33GGLNKRH4NLDLGzAKeBp4XkQ3APmywUEop1YFC2kdgjJkNzG5Udo/fdg1waSjroJRSqmU6110ppSKcBgKllIpwGgiUUirCaSBQSqkI1+Wyj4pIEbD1EF+eTaNZyxFArzky6DVHhsO55n7GmJxgO7pcIDgcIrKouVwb3ZVec2TQa44MobpmbRpSSqkIp4FAKaUiXKQFghnhrkAY6DVHBr3myBCSa46oPgKllFJNRdodgVJKqUY0ECilVISLmEAgIpNFZJ2IbBCRO8Ndn/YiIs+IyB4RWelXlikiH4rIeucxwykXEXnY+R18LSJHh6/mh05E+ojIXBFZLSKrRORmp7zbXreIxIvIAhFZ7lzzfU75ABH5yrm2V5yU74hInPN8g7O/fzjrf6hEJEpElorIO87zbn29ACKyRURWiMgyEVnklIX0bzsiAoGIRAGPAVOA4cCVIjI8vLVqN88CkxuV3Ql8bIwZAnzsPAd7/UOcn+nAEx1Ux/bWANxqjBkOTABudP49u/N11wKnGWOOAsYAk0VkAvAg8FdjzGCgBLjeOf56oMQp/6tzXFd0M7DGA6hlSQAABFBJREFU73l3v16vU40xY/zmDIT2b9sY0+1/gInAB37P7wLuCne92vH6+gMr/Z6vA3o5272Adc72k8CVwY7ryj/A28CZkXLdQCKwBLsGeDEQ7ZQf+DvHrgMy0dmOdo6TcNe9jdeZ73zonQa8g11SuNter991bwGyG5WF9G87Iu4IgDxgu9/zAqesu8o1xux0tncBuc52t/s9OE0AY4Gv6ObX7TSTLAP2AB8CG4FSY0yDc4j/dR24Zmd/GZDVsTU+bA8BPwc8zvMsuvf1ehlgjogsFpHpTllI/7a7xOL16tAZY4yIdMsxwiKSDPwb+KkxZr//Auzd8bqNMW5gjIikA28CR4a5SiEjIucBe4wxi0XklHDXp4NNMsYUikgP4EMRWeu/MxR/25FyR1AI9PF7nu+UdVe7RaQXgPO4xynvNr8HEYnBBoEXjTFvOMXd/roBjDGlwFxs00i6iHi/0Plf14FrdvanAXs7uKqH4wRgqohsAV7GNg/9je57vQcYYwqdxz3YgD+eEP9tR0ogWAgMcUYcxGLXRp4V5jqF0izg2872t7Ft6N7ya52RBhOAMr/bzS5D7Ff/p4E1xpi/+O3qttctIjnOnQAikoDtE1mDDQiXOIc1vmbv7+IS4BPjNCJ3BcaYu4wx+caY/tj/r58YY66mm16vl4gkiUiKdxs4C1hJqP+2w90x0oEdMOcA32DbVX8R7vq043W9BOwE6rHtg9dj20Y/BtYDHwGZzrGCHT21EVgBjAt3/Q/xmidh21G/BpY5P+d05+sGRgNLnWteCdzjlA8EFgAbgNeAOKc83nm+wdk/MNzXcBjXfgrwTiRcr3N9y52fVd7PqlD/bWuKCaWUinCR0jSklFKqGRoIlFIqwmkgUEqpCKeBQCmlIpwGAqWUinAaCJTqQCJyijeTplKdhQYCpZSKcBoIlApCRKY5+f+XiciTTsK3ChH5q7MewMcikuMcO0ZE5jv54N/0yxU/WEQ+ctYQWCIig5zTJ4vI6yKyVkReFP8kSUqFgQYCpRoRkWHA5cAJxpgxgBu4GkgCFhljRgCfAb9yXvJP4A5jzGjs7E5v+YvAY8auIXA8dgY42GypP8WujTEQm1dHqbDR7KNKNXU6cAyw0PmynoBN8uUBXnGOeQF4Q0TSgHRjzGdO+XPAa06+mDxjzJsAxpgaAOd8C4wxBc7zZdj1JL4I/WUpFZwGAqWaEuA5Y8xdAYUiv2x03KHmZ6n123aj/w9VmGnTkFJNfQxc4uSD964X2w/7/8Wb+fIq4AtjTBlQIiInOuXXAJ8ZY8qBAhG5wDlHnIgkduhVKNVK+k1EqUaMMatF5G7sKlEubGbXG4FKYLyzbw+2HwFsWuC/Ox/0m4DrnPJrgCdF5NfOOS7twMtQqtU0+6hSrSQiFcaY5HDXQ6n2pk1DSikV4fSOQCmlIpzeESilVITTQKCUUhFOA4FSSkU4DQRKKRXhNBAopVSE+395KJ9UpJx7tgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxyGKvNgc50N"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf2mTXHp_xe6",
        "outputId": "6b872381-6776-43bb-9961-9483ddeb7119"
      },
      "source": [
        "model_name = 'umar.h5'\n",
        "save_dir = os.path.join(os.getcwd(), 'Trained_Models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/Trained_Models/umar.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcFvDUMSdQYx"
      },
      "source": [
        "import json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_RmLR9udVFb",
        "outputId": "caa940cb-2044-4d8c-e200-1556ffe3a959"
      },
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./Trained_Models/umar.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "accuracy: 90.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rti9iycgdhjs",
        "outputId": "b52091ed-3794-4ea8-90ed-c8426b749ac8"
      },
      "source": [
        "preds = loaded_model.predict(x_testcnn, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 48ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHVEm-ydxUn"
      },
      "source": [
        "preds1=preds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "23uTvQm4d-d4",
        "outputId": "ead3ecb1-2cd3-4e2f-bb9e-9b470c8f87cc"
      },
      "source": [
        "import pandas as pd\n",
        "abc = preds1.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((abc)))\n",
        "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
        "preddf[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictedvalues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  predictedvalues\n",
              "0              03\n",
              "1              04\n",
              "2              02\n",
              "3              04\n",
              "4              04\n",
              "5              03\n",
              "6              03\n",
              "7              04\n",
              "8              01\n",
              "9              03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwmcfx03emH9"
      },
      "source": [
        "actual=y_test.argmax(axis=1)\n",
        "abc123 = actual.astype(int).flatten()\n",
        "actualvalues = (lb.inverse_transform((abc123)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "jIXdgDARerDE",
        "outputId": "69a3339e-80be-4c93-d2a9-0cd65381357f"
      },
      "source": [
        "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
        "actualdf[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actualvalues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  actualvalues\n",
              "0           03\n",
              "1           04\n",
              "2           04\n",
              "3           04\n",
              "4           04\n",
              "5           03\n",
              "6           04\n",
              "7           02\n",
              "8           01\n",
              "9           03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "GC4QyKFYevli",
        "outputId": "4aaf3a38-dc00-4c2e-c328-695d03c05583"
      },
      "source": [
        "finaldf = actualdf.join(preddf)\n",
        "finaldf[130:140]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actualvalues</th>\n",
              "      <th>predictedvalues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>01</td>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>04</td>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>01</td>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    actualvalues predictedvalues\n",
              "130           02              02\n",
              "131           02              02\n",
              "132           01              01\n",
              "133           02              02\n",
              "134           02              02\n",
              "135           02              02\n",
              "136           04              04\n",
              "137           01              01\n",
              "138           02              02\n",
              "139           02              02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zTM6eu2_e5ca",
        "outputId": "457a302f-b37a-40eb-c6dd-e1ea09838229"
      },
      "source": [
        "finaldf.groupby('actualvalues').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictedvalues</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>actualvalues</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>01</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02</th>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>04</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              predictedvalues\n",
              "actualvalues                 \n",
              "01                         39\n",
              "02                         44\n",
              "03                         31\n",
              "04                         40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkNTD6LPe8rv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ6DyqacMcdJ",
        "outputId": "36093bb1-e1e0-4bf0-da60-e92cd1dc169d"
      },
      "source": [
        "score = model.evaluate(x_testcnn, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 90.91%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}